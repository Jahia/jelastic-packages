---
# Depends on:
#   - common.yml

actions:
  setupES:
    cmd[${this}]: |-
      es_conf=/etc/elasticsearch/elasticsearch.yml
      ipadd=$(ip a s scope global | awk '$1=="inet" {split($2, ipad, "/"); print ipad[1]}')
      node_name=$(awk -v ipadd=$ipadd '$1==ipadd && $2~/^es_[0-9]+$/ {print $2; exit}' /etc/hosts)
      # some cleaning in case of an update
      sed -e '/^path\.repo/d' \
          -e '/^node\.name/d' \
          -e '/^discovery\.zen\./d' \
          -e '/^discovery\.seed_/d' \
          -e '/^cluster\.initial_/d' \
          -i $es_conf
      sed 's/\(^discovery.type: single-node\)/#\1/' -i $es_conf
      echo "node.name: $node_name" >> $es_conf
      hosts_list=$(awk '$2~/^es_[0-9]+$/ {nodes[$2]} END{asorti(nodes);printf "["; for(n=1;n<=length(nodes);n++){if(n<length(nodes)){sep=", "}else{sep="]"}; printf "\"%s\"%s",nodes[n],sep}}' /etc/hosts)
      echo "cluster.initial_master_nodes: $hosts_list" >> $es_conf
      echo "discovery.seed_hosts: $hosts_list" >> $es_conf
      echo "discovery.zen.minimum_master_nodes: $(expr ${nodes.es.length} / 2 + 1)" >> $es_conf
      systemctl enable elasticsearch
      systemctl restart elasticsearch

  setupDatadogAgentEs:
    - setGlobalRepoRootUrl
    - cmd[${this}]: |-
        chmod 755 /var/log/elasticsearch/
        chmod 755 /var/log/elasticsearch/*.log -R
        sed -i "s/\(url: http:\/\/\).*\(:.*\)/\1${HOSTNAME}\2/" /etc/datadog-agent/conf.d/elastic.d/conf.yaml
        mkdir /etc/datadog-agent/conf.d/jelastic.d /var/log/jelastic-packages
        chown root:root /var/log/jelastic-packages
        chown dd-agent: /etc/datadog-agent/conf.d/jelastic.d
        curl -fLSso /etc/datadog-agent/conf.d/jelastic.d/conf.yaml ${globals.repoRootUrl}/assets/common/dd_agent_jelastic_package_conf.yml || exit 1

        # Temporarily disable IO check (cf. PAAS-1543)
        mv /etc/datadog-agent/conf.d/io.d/conf.yaml.default /etc/datadog-agent/conf.d/io.d/conf.yaml.default.disabled

        systemctl restart crond datadog-agent

  updateReplica:
    - cmd[${nodes.cp.first.id}]: |-
        curl -s \
          -u $UNOMI_ELASTICSEARCH_USERNAME:$UNOMI_ELASTICSEARCH_PASSWORD \
          https://$UNOMI_ELASTICSEARCH_ADDRESSES/_cat/indices \
          | awk -v repl=${this.replica} '$6!=repl {print $3}' | while read index; do
            curl -s \
              -u $UNOMI_ELASTICSEARCH_USERNAME:$UNOMI_ELASTICSEARCH_PASSWORD \
              -H "Content-Type: application/json" \
              -XPUT https://$UNOMI_ELASTICSEARCH_ADDRESSES/$index/_settings \
              -d '{"index":{"number_of_replicas": ${this.replica} }}' 2>>${this.logsPath}
        done

  calculateNumberOfReplicas:
    - if(nodes.es.length > 1):
        - if(nodes.es.length > 4):
          - setGlobals:
              - replica: 2
        - else:
          - setGlobals:
              - replica: 1
    - else:
        setGlobals:
          - replica: 0

  setReplica:
    - calculateNumberOfReplicas
    - forEach(nodes.cp):
        cmd[${@i.id}]: |-
          setenv=$(find /opt/jcustomer/jcustomer/bin -name setenv)
          # test if not update needed
          actual=$(awk -F'=' '/UNOMI_ELASTICSEARCH_MONTHLYINDEX_REPLICAS/ {print $NF}' $setenv)
          if [ ! -z "$actual" ]; then
            if [ $actual -eq ${globals.replica} ]; then
              echo "$(hostname) already get the good replica parameters (${globals.replica})"
              exit 0
            fi
          fi
          # some cleaning in case of an update
          sed '/^export UNOMI_ELASTICSEARCH/d' -i $setenv
          echo "export UNOMI_ELASTICSEARCH_MONTHLYINDEX_REPLICAS=${globals.replica}" >> $setenv
          echo "export UNOMI_ELASTICSEARCH_DEFAULTINDEX_REPLICAS=${globals.replica}" >> $setenv
          systemctl is-active --quiet karaf && systemctl restart karaf || exit 0
        user: root

  setShardAllocation:
    # Parameters;
    #   - allocation: to be set to strings "primaries" or "null"
    #   - target
    - if("${this.allocation}" == "primaries"):
        - set:
            rule: "\"primaries\""
    - elif("${this.allocation}" == "null"):
        - set:
            rule: "null"
    - log: "Set cluster.routing.allocation.enable to ${this.rule}"
    - cmd[${this.target}]: |-
        # If ${this.rule} is "null" then it's possible that ES daemon is not yet
        # started so we wait a bit for it
        # We check if ES daemon is started with a curl instead of `systemctl is-active`
        # because there is a lag between the time the service is considered active
        # and the node is reachable via curl
        if [ "${this.rule}" == "null" ]; then
          maxi=128
          i=1
          until (curl -sf "${HOSTNAME}:9200/_cluster/health?timeout=1s" >/dev/null); do
            if [ $i -gt $maxi ]; then
              echo "Elasticsearch is still not started, aborting..."
              exit 1
            fi
            echo "Waiting for ES to be started $i/$maxi"
            ((i++))
            sleep 2
          done
        fi

        curl -s -H 'Content-Type: application/json' -XPUT \
          -d '{"persistent":{"cluster.routing.allocation.enable": ${this.rule} }}' \
          http://${HOSTNAME}:9200/_cluster/settings

  forceESFlush:
    # Parameters:
    #   - target
    - cmd[${this.target}]: |-
        es_version=$(curl http://${HOSTNAME}:9200/ -s | jq -r .version.number)
        if printf '%s\n%s' '7.6.0' "$es_version" | sort -CV; then
          endpoint="_flush"         # since 7.6.0
        else
          endpoint="_flush/synced"  # deprecated since 7.6.0
        fi

        flush() {
          failed=$(curl -s -XPOST http://${HOSTNAME}:9200/${endpoint} | jq -r .[].failed | awk '{f=f+$1} END{print f}')
          if [ $failed -eq 0 ]; then
            return 0
          else
            return 1
          fi
        }

        # initiate flush and wait a few
        curl -s -XPOST http://${HOSTNAME}:9200/${endpoint}
        sleep 10

        # now check no flush failed
        maxi=66
        i=1
        until flush; do
          if [ $i -gt $maxi ]; then
            echo "ES node still have failure(s) on flush, aborting..."
            exit 1
          fi
          echo "flush iteration $i/$maxi"
          ((i++))
          sleep 2
        done

  redeployEsNodes:
    - if(nodes.es.length == 1):
        - log: "Stopping Karaf..."
        - manageSystemdService:
            target: cp
            unit: karaf
            action: stop

        - log: "Redeploying Elasticsearch node..."
        - api: environment.control.redeploycontainersbygroup
          nodeGroup: es
          tag: ${nodes.es.first.version}
          useExistingVolumes: true

        - log: "Starting Karaf..."
        - manageSystemdService:
            target: cp
            unit: karaf
            action: start
        - checkEsClusterStatus
    - else:
        - forEach(nodes.es):
            - log: "Redeploying Elasticsearch node ${@i.id}..."
            - api: environment.control.RedeployContainerById
              nodeId: ${@i.id}
              tag: ${nodes.es.first.version}
              useExistingVolumes: true
              skipReinstall: false
            - checkEsClusterStatus

  checkEsClusterStatus:
    # Every second, we check cluster health. If curl fails with a 10s timeout, then exit 1.
    # For 3-nodes clusters, until status is green & actual nodes number equals nodes.es.length,
    # we check that the number of active shards is increasing (meaning the node is not fully
    # initialized yet). If it is still not after 10s, exit 1.
    # For single node ES, we check green or yellow status
    - cmd[${nodes.es.first.id}]: |-
        health_file="/tmp/es_cluster_health.json"
        i=0
        prev_active_shards=0
        total_nodes_count=${nodes.es.length}
        # Single ES node: we check green or yellow status
        healthcheck_condition='[[ "$status" == "green" ]] || [[ "$status" == "yellow" ]]'

        # 3-nodes cluster: we check green status only
        if [ $total_nodes_count -gt 1 ]; then
          healthcheck_condition='[[ "$status" == "green" ]] && [ $real_nodes_count -eq $total_nodes_count ]'
        fi

        while [ $i -lt 20 ]; do
          curl -Ssf 'es:9200/_cluster/health?timeout=10s' > $health_file || (rm -f $health_file; exit 1)
          status=$(cat $health_file | jq -r '.status')
          real_nodes_count=$(cat $health_file | jq '.number_of_nodes')
          if eval $healthcheck_condition; then
            exit 0
          fi
          active_shards=$(cat $health_file | jq ".active_shards")
          [ $active_shards -eq $prev_active_shards ] && ((i=i+1)) || i=0
          prev_active_shards=$active_shards
          sleep 1
        done
        echo "[ERROR] There is an issue with the cluster, please check" 1>&2
        exit 1
      user: root

  checkElasticsearchDatadogCustomChecks:
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: elastic

  setAwsSnapshotRepository:
    # Parameters:
    #   - repositoryName
    #   - backupName
    #   - region
    #   - account
    #   - logsPath
    #   - awsAccessKeyId
    #   - awsSecretAccessKey
    - cmd[${nodes.cp.first.id}]: |-
        aws_access_key="${this.awsAccessKeyId}"
        aws_secret_key="${this.awsSecretAccessKey}"
        curl \
          -H 'Content-Type: application/json' \
          -u $UNOMI_ELASTICSEARCH_USERNAME:$UNOMI_ELASTICSEARCH_PASSWORD \
          -XPUT "https://$UNOMI_ELASTICSEARCH_ADDRESSES/_snapshot/${this.repositoryName}?verify=false&pretty" \
          -d"{
            \"type\": \"s3\",
            \"settings\": {
                \"bucket\": \"${this.account}\",
                \"region\": \"${this.region}\",
                \"base_path\" : \"${this.backupName}/elasticsearch\",
                \"access_key\": \"$aws_access_key\",
                \"secret_key\": \"$aws_secret_key\"
            }
          }" 2>>${this.logsPath} || exit 1

  setAzureSnapshotRepository:
    # Parameters:
    #   - repositoryName
    #   - backupName
    #   - logsPath
    #   - awsAccessKeyId
    #   - awsSecretAccessKey
    #   - operation
    #   - account
    - getAzureElasticsearchSecret:
        awsAccessKeyId: ${this.awsAccessKeyId}
        awsSecretAccessKey: ${this.awsSecretAccessKey}
        backupName: ${this.backupName}
        operation: "${this.operation}"
        account: ${this.account}
        logsPath: ${this.logsPath}

    - cmd[${nodes.cp.first.id}]: |-
        curl \
          -H 'Content-Type: application/json' \
          -u $UNOMI_ELASTICSEARCH_USERNAME:$UNOMI_ELASTICSEARCH_PASSWORD \
          -XPUT "https://$UNOMI_ELASTICSEARCH_ADDRESSES/_snapshot/${this.repositoryName}?verify=false&pretty" \
          -d"{
            \"type\": \"azure\",
            \"settings\": {
                \"container\": \"${this.backupName}\",
                \"base_path\" : \"elasticsearch\",
                \"account\" : \"${this.account}\",
                \"key\" : \"${globals.azure_secret}\"
            }
          }" 2>>${this.logsPath} || exit 1

  getAzureElasticsearchSecret:
    # Parameters:
    #   - awsAccessKeyId
    #   - awsSecretAccessKey
    #   - backupName
    #   - operation
    #   - account
    #   - logsPath
    # Returns:
    #   ${globals.azure_secret}
    - cmd[${nodes.cp.first.id}]: |-
        export AWS_ACCESS_KEY_ID="${this.awsAccessKeyId}" AWS_SECRET_ACCESS_KEY="${this.awsSecretAccessKey}"
        cd jelastic_backup
        python3 elasticsearch.py --bucketname ${this.account} --backupname ${this.backupName} --cloudprovider=azure --operation=${this.operation} 2>>${this.logsPath} || exit 1
    - cmd[${nodes.cp.first.id}]: |-
        cat /tmp/azurecred
        rm -f /tmp/azurecred
    - setGlobals:
        azure_secret: "${response.out}"
    - if ("${globals.azure_secret}" == ""):
        - return:
            type: error
            message: "An error occurred during backup repository configuration."
