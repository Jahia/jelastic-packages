---
# Depends on:
#   - common.yml
#   - jahia.yml

actions:
  ####################
  # database related #
  ####################
  updateMysqlUser:
    - cmd [${this}]: sed 's;\(^mysql.*\)/home/jelastic/.*;\1/var/lib/mysql/:/sbin/nologin;' /etc/passwd

  installDatabase:
    # Parameters:
      #   - user: DB username
      #   - __secret__password: DB user's password
    - setJelasticUserAsRoot: sqldb
    - updateMysqlUser: sqldb
    - log: "## Setup MariaDB logrotate"
    - setGlobalRepoRootUrl
    - cmd[sqldb]: |-
        systemctl stop mysql
        sudo -u mysql mysqld_safe --skip-grant-tables --skip-networking &
        sleep 5  # be sure that the daemon is launched
        # allow root user to authenticate
        for u in root mysql; do
          mysql -e "flush privileges; alter user ${u}@localhost identified via unix_socket; flush privileges;"
        done
        pkill 'mysqld_safe|mariadbd'
        sleep 5  # be sure that the daemon is stopped
        # Securing possible blocking issues with jelastic/mariadb:10.4.13 with next 3 lines
        [ -f /etc/mysql/conf.d/master.cnf ] && rm -f /etc/mysql/conf.d/master.cnf
        [ -f /etc/mysql/conf.d/slave.cnf ] && rm -f /etc/mysql/conf.d/slave.cnf
        curl --retry 6 -fLSso /etc/mysql/conf.d/mysql.cnf ${globals.repoRootUrl}/assets/database/mysql.cnf || exit 1
        curl --retry 6 -fLSso /etc/logrotate.d/mysql ${globals.repoRootUrl}/assets/database/logrotate_mysql || exit 1
        chmod 644 /etc/logrotate.d/mysql
        curl --retry 6 --create-dirs -fLSso /var/lib/jelastic/customizations/jahia_override.lib ${globals.repoRootUrl}/assets/database/jahia_override.lib || exit 1
        chown -R mysql:mysql /var/lib/jelastic/customizations
        logrotate -f /etc/logrotate.d/mysql
        systemctl start mysql
        mysql -e "set global key_buffer_size = 128*1024*1024; set global myisam_sort_buffer_size = 128*1024*1024; set global wsrep_sst_auth = 'mysql:'; set global wsrep_sst_method = 'mariabackup';"
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred during mariadb setup."
    - if (nodes.sqldb.length > 1):
        - installGaleraCluster
    - else:
        # Trigger mariabackup installation
        - cmd [sqldb]: systemctl restart mysql
    - log: "## Create DX's Jahia database and user"
    - cmd[${nodes.sqldb.master.id}]: |-
        __secret__password="${this.__secret__password}"
        mysql -e "CREATE DATABASE IF NOT EXISTS jahia CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
        mysql -e "grant all privileges on jahia.* to '${this.user}'@'%' identified by '$__secret__password';"
        mysql -e "flush privileges;"
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when creating jahia database."

  createDataDogUser:
    - log: "## Create Datadog database user"
    - cmd[${nodes.sqldb.master.id}]: |-
        exists=$(mysql -sNe "select count(*) from  mysql.user where User='datadog';")
        if [ $exists -lt 2 ]; then
          mysql -e "CREATE OR REPLACE USER 'datadog'@'localhost' IDENTIFIED BY '${DB_USER_DATADOG}';"
          mysql -e "CREATE OR REPLACE USER 'datadog'@'%' IDENTIFIED BY '${DB_USER_DATADOG}';"
          mysql -e "GRANT REPLICATION CLIENT ON *.* TO 'datadog'@'localhost' WITH MAX_USER_CONNECTIONS 5;"
          mysql -e "GRANT PROCESS ON *.* TO 'datadog'@'localhost';"
          mysql -e "GRANT SELECT ON performance_schema.* TO 'datadog'@'localhost';"
          mysql -e "GRANT SELECT ON jahia.JR_J_LOCAL_REVISIONS TO 'datadog'@'%';"
        fi
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when creating datadog database user."

  setupDatadogAgentSql:
    - createDataDogUser
    - log: "## Finalize Datadog agent setup on ${this}"
    - setGlobalRepoRootUrl
    - set:
        cluster: "false"
    - if (nodes.sqldb.length > 1):
        set:
          cluster: "true"
    - installLatestDatadogAgent: ${this}
    - cmd [${this}]: |-
        NODE_NAME=${HOSTNAME/-*}
        echo "hostname: ${_ROLE}.${NODE_NAME#node}" >> /etc/datadog-agent/datadog.yaml
        sed -i 's/# logs_enabled: false/logs_enabled: true/' /etc/datadog-agent/datadog.yaml
        echo "tags:" >> /etc/datadog-agent/datadog.yaml
        echo " - product:jahia" >> /etc/datadog-agent/datadog.yaml
        echo " - version:${DX_VERSION}" >> /etc/datadog-agent/datadog.yaml
        echo " - envname:${env.envName}" >> /etc/datadog-agent/datadog.yaml
        echo " - provide:${_PROVIDE}" >> /etc/datadog-agent/datadog.yaml
        echo " - role:${_ROLE}" >> /etc/datadog-agent/datadog.yaml
        echo "---" > /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "logs:" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "  - type: file" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    path: /var/log/mysql/mysqld.log" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    source: mysql" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    service: mysql" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    log_processing_rules:" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "      - type: multi_line " >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "        name: new_log_start_with_date" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "        pattern: \d{4}\-(0?[1-9]|1[012])\-(0?[1-9]|[12][0-9]|3[01])" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "  - type: file" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    path: /var/log/mysql/slow-queries.log" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    source: mysql" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    service: mysql" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "init_config:" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "instances:" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "  - server: 127.0.0.1" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    username: datadog" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    password: ${DB_USER_DATADOG}" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    sock: /var/lib/mysql/mysql.sock" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    tags:" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "      - 'env:${env.envName}'" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "      - 'role:database'" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "    options:" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       replication: false" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       galera_cluster: ${this.cluster}" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       extra_status_metrics: true" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       extra_innodb_metrics: true" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       extra_performance_metrics: true" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       schema_size_metrics: true" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        echo "       disable_innodb_metrics: false" >> /etc/datadog-agent/conf.d/mysql.d/conf.yaml
        curl --retry 6 -fLSso /etc/datadog-agent/checks.d/check_galera_wsrep_ready_status.py ${globals.repoRootUrl}/assets/database/check_galera_wsrep_ready_status.py || exit 1
        chown dd-agent: /etc/datadog-agent/checks.d/check_galera_wsrep_ready_status.py
        ln -s /etc/datadog-agent/conf.d/mysql.d/conf.yaml /etc/datadog-agent/conf.d/check_galera_wsrep_ready_status.yaml
        chown -h dd-agent: /etc/datadog-agent/conf.d/check_galera_wsrep_ready_status.yaml
        mkdir /etc/datadog-agent/conf.d/jelastic.d /var/log/jelastic-packages
        chown mysql:root /var/log/jelastic-packages
        chown dd-agent: /etc/datadog-agent/conf.d/jelastic.d
        curl --retry 6 -fLSso /etc/datadog-agent/conf.d/jelastic.d/conf.yaml ${globals.repoRootUrl}/assets/common/dd_agent_jelastic_package_conf.yml || exit 1
        curl --retry 6 -fLSso /usr/local/bin/set_dd_tags.sh ${globals.repoRootUrl}/assets/common/set_dd_tags.sh || exit 1
        curl --retry 6 -fLSso /etc/cron.d/set_dd_tags_cron ${globals.repoRootUrl}/assets/common/set_dd_tags_cron || exit 1
        chmod u+x /usr/local/bin/set_dd_tags.sh
        chmod 644 /var/log/mysql/mysqld.log
        chmod 644 /var/log/mysql/slow-queries.log  > /dev/null 2>&1
        systemctl restart crond datadog-agent
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when installing datadog agent on a mariadb node."

  checkMariadbHealth:
    # Parameters:
    #   target: target node
    #   maxDuration (optional): will retry every 5 sec until max duration value is reached. Default is 0 (single check). Max duration unit is seconds
    - cmd [${this.target}]: |-
        i=0
        timeout=${this.maxDuration:0}
        MYSQL_IS_RUNNING=0
        while [ $MYSQL_IS_RUNNING -eq 0 ] || [ $i -lt $timeout ]; do
          if systemctl status mysql > /dev/null; then
            if mysqladmin -s processlist 1>/dev/null; then
              MYSQL_IS_RUNNING=1
            else
              echo "[ERROR] Can't connect to mysql instance, exiting" 1>&2
            fi
          else
            echo "[ERROR] Mariadb service is not running, exiting" 1>&2
          fi
          i=$((i + 5))
        done
        if [ $MYSQL_IS_RUNNING -eq 0 ]; then
          exit 1
        fi

  getGaleraNodeNameIndex:
    - cmd [${this}]: |-
        my_ip=$(grep $(hostname) /etc/hosts | awk '{print $1}')
        awk -v my_ip="$my_ip galera" '$0 ~my_ip {print $2}' /etc/hosts
    - setGlobals:
        galeraNodeNameIndex: "${response.out}"

  mysqlService:
    - if ("${this.action}" == "enable"):
        - cmd [${this.target}]: |-
            sed -i '/^\/var\/lib\/jelastic\/overrides\/envinfo.lib/d' /etc/jelastic/redeploy.conf
            rm /var/lib/jelastic/overrides/envinfo.lib || exit 0
    - if ("${this.action}" == "disable"):
        - cmd [${this.target}]: |-
            echo "SERVICE=''" > /var/lib/jelastic/overrides/envinfo.lib
            echo "/var/lib/jelastic/overrides/envinfo.lib" >> /etc/jelastic/redeploy.conf

  ##################
  # galera related #
  ##################
  installGaleraCluster:
    - setGlobalRepoRootUrl
    - resetCluster
    - initialSetup
    - setupSeeds
    - forEach(i:nodes.sqldb):
        setupInstance:
          id: "${@i.id}"
    - cmd[${nodes.sqldb.master.id}]: "systemctl stop mysql; sleep 5; galera_new_cluster;"
    - forEach(n:nodes.sqldb):
        if (!${@n.ismaster}):
          cmd[${@n.id}]: "jem service restart"

  setupInstance:
    - cmd[${this.id}]: |-
        sed -i "s/server_id.*/server_id = $(echo '${env.region}' | md5sum | grep -Eo "[[:digit:]]{3}" | head -n1)/" /etc/mysql/conf.d/galera.cnf
        sed -i "s/bind-address.*/bind-address = node${this.id}/" /etc/mysql/conf.d/galera.cnf
        sed -i "s/report_host.*/report_host = node${this.id}/" /etc/mysql/conf.d/galera.cnf
        sed -i "s/wsrep_cluster_name.*/wsrep_cluster_name = galera-cluster/" /etc/mysql/conf.d/galera.cnf
        sed -i "s/wsrep_node_name.*/wsrep_node_name = node${this.id}/" /etc/mysql/conf.d/galera.cnf
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred during galera cluster setup."

  initialSetup:
    - setNodeDisplayName[sqldb]: Galera
    - setGlobalRepoRootUrl
    - cmd[sqldb]: |-
        curl -fLSso /etc/mysql/conf.d/galera.cnf ${globals.repoRootUrl}/assets/database/galera.cnf &>> /var/log/run.log || exit 1
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred during galera cluster setup."

  stopGalera:
    - if (nodes.sqldb.length > 1):
        - forEach(nodes.sqldb):
            - if (${@i.id} != ${nodes.sqldb.first.id}):
                - log: "Stopping MariaDB on node ${@i.id}..."
                - cmd[${@i.id}]: |-
                    systemctl stop mysql || exit 1
                    cat /var/lib/mysql/grastate.dat || true
        - log: "Stopping MariaDB on node ${nodes.sqldb.first.id}..."
        - cmd [${nodes.sqldb.first.id}]: |-
            systemctl stop mysql || exit 1
            cat /var/lib/mysql/grastate.dat || true
        - cmd [sqldb]: |-
            systemctl disable mysql
    - else:
        - cmd [sqldb]: |-
            systemctl stop mysql || exit 1

  setupSeeds:
    script: |
      var resp = jelastic.env.control.GetEnvInfo('${env.envName}', session);
      if (resp.result != 0) return resp;
      var intIP = [];
      for (var i = 0, n = resp.nodes; i < n.length; i++)
        n[i].nodeGroup == "sqldb" ? intIP.push(n[i].intIP) : 0
      resp = {result:0, onAfterReturn: {}};
      resp.onAfterReturn['cmd[sqldb]'] = 'sed -i "s|wsrep_cluster_address.*|wsrep_cluster_address = gcomm://'+ intIP.join(',') +'|g " /etc/mysql/conf.d/galera.cnf';
      resp.onAfterReturn['user'] = 'root';
      return resp;

  resetCluster:
    - cmd[sqldb]: |-
        [ -f /etc/mysql/conf.d/galera.cnf ] && rm -f /etc/mysql/conf.d/galera.cnf
        [ -f /var/lib/mysql/grastate.dat ] && rm -f /var/lib/mysql/grastate.dat
        [ -f /var/lib/mysql/gvwstate.dat ] && rm -f /var/lib/mysql/gvwstate.dat
        [ -f /var/lib/mysql/galera.cache ] && rm -f /var/lib/mysql/galera.cache
        (systemctl stop mysql; pkill -9 mysql; systemctl start mysql) 2> /dev/null
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred during galera cluster init."

  checkGaleraClusterHealth:
    - cmd [${this}]: |-
        if [ -f /var/lib/mysql/grastate.dat ]; then
          if [ "$(mysql -Ns -e "show global status like 'wsrep_local_state_comment'" | awk '{print $NF}')" != "Synced"  ]; then
            echo "[ERROR] Galera cluster not synced, exiting" 1>&2 && exit 1
          fi
        fi

  checkMariadbDatadogCustomChecks:
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: mysql

  stopGaleraNode:
    cmd[${this}]: |-
      systemctl stop mysql || exit 1
      if [ -f /var/lib/mysql/grastate.dat ]; then
        cat /var/lib/mysql/grastate.dat
      else
        echo "$HOSTNAME is not in a cluster"
      fi
      systemctl stop mysql

  startGaleraNode:
    # Parameters:
    #   - target
    #   - bootstrap_cluser: (Optional, default value: false) Set to true if you want to bootstrap the cluster
    - set:
        bootstrap: false
    - if ("${this.bootstrap_cluster}" == "true"):
        - set:
            bootstrap: true
    - cmd [${this.target}]: |-
        if ${this.bootstrap}; then
          galera_new_cluster
        else
          systemctl start mysql
        fi
        rc=$?
        mariadb-upgrade --check-if-upgrade-is-needed && mariadb-upgrade  # in case a backup from a previous minor MariaDB has just been restored
        if [ ! -f /var/lib/mysql/grastate.dat ]; then
          echo "$HOSTNAME is not in a cluster, exiting"
          exit $rc
        fi
        i=1
        it=66
        until [ "$(mysql -Ns -e "show global status like 'wsrep_local_state_comment'" | awk '{print $NF}')" == "Synced"  ]; do
          if [ $i -ge $it ]; then
            echo "Too long to start, something is wrong here... EXITING"
            exit 1
          fi
          # As long as there is a mariabackup command running, we don't increment the timeout count
          if pgrep wsrep_sst_maria; then
            echo "$(date) SSTs sync still in progress"
            sleep 15
          else
            echo "$(date) not ready yet (iteration $i/$it)"
            ((i++))
            sleep 1
          fi
        done
        echo "Node $HOSTNAME is now Synced !"

  rollingRestartGaleraNodes:
    - if (nodes.sqldb.length > 1):
      - getGaleraMaster
      - forEach(nodes.sqldb): # Only restart no master nodes. It allows to change master node only once
          - getGaleraNodeNameIndex: ${@i.id}
          - if ("${globals.galeraNodeNameIndex}" != "${globals.galeraMasterIndex}"):
            - log: "Restarting MariaDB on node ${@i.id}..."
            - setDonorNode:
                target : ${@i.id}
            - stopGaleraNode: ${@i.id}
            - startGaleraNode:
                target: ${@i.id}
            - sleep:
              - milliseconds: 15000
          - else:
            - setGlobals:
                origMasterId: ${@i.id}

      - script: |-
          masterIndex = "${globals.galeraMasterIndex}".slice(-1);
          newMasterIndex = ((masterIndex + 1) % 3) + 1
          return {'result':0, 'newMasterIndex': newMasterIndex}

      - proxysqlSwitchMaster:
          target: ${response.newMasterIndex}

      - setDonorNode:
          target: ${globals.origMasterId}

      - stopGaleraNode: ${globals.origMasterId}
      - startGaleraNode:
          target: ${globals.origMasterId}
    - else:
      - stopGaleraNode: ${nodes.sqldb.first}
      - startGaleraNode:
          target: ${nodes.sqldb.first}

  startGaleraCluster:
    # First of all we bootstrap the first node (should be the last one to be stopped,
    # therefore the first one to be started)
    - cmd [${nodes.sqldb.first.id}]: |-
        sed -i 's/safe_to_bootstrap:.*/safe_to_bootstrap: 1/' /var/lib/mysql/grastate.dat
    - startGaleraNode:
        target: ${nodes.sqldb.first.id}
        bootstrap_cluster: true
    # Then we start all other nodes
    - forEach (nodes.sqldb):
        if (${@i.id} != ${nodes.sqldb.first.id}):
          - cmd[${@i.id}]: |-
              sed -i 's/safe_to_bootstrap:.*/safe_to_bootstrap: 0/' /var/lib/mysql/grastate.dat
          - startGaleraNode:
              target: ${@i.id}

  setDonorNode:
    # Configure the wsrep donor node as a non master node.
    # !!!!
    # It does not restart mysql, just update the configuration file
    # Don't use this action on environments having a single db node (obviously...)
    # !!!!
    # Parameters
    # - target: The node id to update
    - getGaleraMaster
    - forEach(nodes.sqldb):
        - if ("${@i.id}" != "${this.target}"):
          - getGaleraNodeNameIndex: ${@i.id}
          - if ("${globals.galeraNodeNameIndex}" != "${globals.galeraMasterIndex}"):
              - cmd[${@i.id}]: cat /etc/mysql/conf.d/galera.cnf  |awk '$1 == "wsrep_node_name" {print $3}'
              - set:
                  donorNode: ${response.out}
    - cmd[${this.target}]: |-
        sed -i "/wsrep_sst_donor/d" /etc/mysql/conf.d/galera.cnf
        echo "wsrep_sst_donor = ${this.donorNode}," >> /etc/mysql/conf.d/galera.cnf

  checkGaleraClusterSize:
    # Ensure the cluster size match the node count
    - cmd[${nodes.sqldb.first.id}]: |-
        mysql -Nse "show global status like 'wsrep_cluster_size';" | awk '{print $NF}'
    - if ("${response.out}" == "${nodes.sqldb.length}"):
        setGlobals:
          galeraClusterSizeOk: True
    - else:
        setGlobals:
          galeraClusterSizeOk: False

  redeployGaleraClusterNodes:
    - if (nodes.sqldb.length > 1):
        - checkGaleraClusterHealth: sqldb
        - checkGaleraClusterSize
        - if (!${globals.galeraClusterSizeOk}):
            return:
              type: error
              message: "Galera cluster size is wrong. Aborting"
    - getGaleraMaster
    - forEach(nodes.sqldb): # Only redeploy no master nodes. It allows to change master node only once
        - log: "Redeploying MariaDB on node ${@i.id}..."
        - getGaleraNodeNameIndex: ${@i.id}
        - if ("${globals.galeraNodeNameIndex}" != "${globals.galeraMasterIndex}"):
            - setDonorNode:
                target: ${@i.id}
            - redeployGaleraNode:
                target: ${@i.id}
            - sleep:
                - milliseconds: 15000
        - else:
            - setGlobals:
                origMasterId: ${@i.id}

    - script: |-
        masterIndex = "${globals.galeraMasterIndex}".slice(-1);
        newMasterIndex = ((masterIndex + 1) % 3) + 1
        return {'result':0, 'newMasterIndex': newMasterIndex}

    - proxysqlSwitchMaster:
        target: ${response.newMasterIndex}

    - setDonorNode:
        target: ${globals.origMasterId}
    - redeployGaleraNode:
        target: ${globals.origMasterId}


  redeployGaleraNode:
    # Parameters:
    #   - target: target node id
    - proxysqlSetMariadbBackendStatus:
        targetHost: ${globals.galeraNodeNameIndex}
        newStatus: OFFLINE_SOFT
    - stopGaleraNode: ${this.target}
    - api: environment.control.RedeployContainerById
      nodeId: ${this.target}
      tag: ${globals.targetDockerTag}
      useExistingVolumes: true
      skipReinstall: false
      envName: ${env.envName}
    # We are going to a new if dimension, let's save some information
    - setGlobals:
        currentNode: ${this.target}
    - if (nodes.sqldb.length > 1):
        - checkGaleraClusterHealth: sqldb
        - checkGaleraClusterSize
        - if (!${globals.galeraClusterSizeOk}):
            return:
              type: error
              message: "Galera node ${globals.currentNode} was not able to join the cluster after being redeployed"
    - proxysqlSetMariadbBackendStatus:
        targetHost: ${globals.galeraNodeNameIndex}
        newStatus: ONLINE

