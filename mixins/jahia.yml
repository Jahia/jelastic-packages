---
# Depends on:
#   - common.yml

globals:
  proxysql_cli: "mysql -h 127.0.0.1 -uadmin -padmin -P6032"
  org_jahia_ehcachemanager_maxBytesLocalHeap_dev: 700M
  org_jahia_ehcachemanager_big_maxBytesLocalHeap_dev: 700M
  org_jahia_ehcachemanager_maxBytesLocalHeap_prod: 800M
  org_jahia_ehcachemanager_big_maxBytesLocalHeap_prod_cp: 2500M
  org_jahia_ehcachemanager_big_maxBytesLocalHeap_prod_proc: 700M
  expandImportedFilesOnDisk: "true"
  jahiaFileUploadMaxSize: 268435456
  imageService: ImageMagickImageService
  jahiaImageMagickPath: /usr/bin
  java_opts:
    -DDB_USER=${DB_USER}
    -DDB_PASSWORD=${DB_PASSWORD}
    -DREDIS_PASSWORD=${REDIS_PASSWORD}
    -DMANAGER_USER=${MANAGER_USER}
    -DHOST_NAME=$(hostname)
    -Dcom.sun.management.jmxremote
    -Dcom.sun.management.jmxremote.port=7199
    -Dcom.sun.management.jmxremote.ssl=false
    -Dcom.sun.management.jmxremote.authenticate=false
    -XX:MaxPermSize=512m
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:+PrintConcurrentLocks
    -XX:+UseParallelGC
    -XX:SurvivorRatio=8
    -Xmn1G

actions:
  #################
  # jahia related #
  #################
  onAfterBrowsingScaleOut:
    - setSudoer: ${this.newNode}
    - copyApp: ${this.newNode}
    - setToolsPwd: ${this.newNode}
    - setupDatadogAgentJahia: ${this.newNode}
    - cmd[${this.newNode}]: |-
        if (service tomcat status); then
          echo "Now Restarting Tomcat"
          service tomcat restart
        else
          echo "Now Launching Tomcat"
          service tomcat start
        fi
      user: root

  onAfterRedeployJahiaContainer:
    - cmd[${this}]:
        - service tomcat stop
      user: root
    - getMavenPath
    - env.control.AddContainerEnvVars [cp, proc]:
      vars:
        jahia_cfg_mvnPath: ${globals.jahia_cfg_mvnPath}
    - setSudoer: ${this}
    - getLogEventScript: ${this}
    - if (nodes.sqldb.length == 1):
        - disableDatadogCustomChecks
    - copyApp: ${this}
    - setToolsPwd: ${this}
    - if ("${this}" == "cp"):
        cmd[${this}]:
          - sed -i "s#\(processingServer\s*=\).*#\1 false#g" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
    - setupDatadogAgentJahia: ${this}
    - cmd[${this}]: |-
          touch "/data/digital-factory-data/[persisted-configurations].dorestore"
          chown tomcat: "/data/digital-factory-data/[persisted-configurations].dorestore"
          source /etc/locale.conf
          echo "JAHIA_UPGRADE=$JAHIA_UPGRADE"
          if [ "$JAHIA_UPGRADE" == "true" ]; then
            echo "This is an upgrade, processing's tomcat will not be restarted now"
          else
            echo "This is a regular redeploy, restart tomcat now"
            service tomcat start
          fi
      user: root

    - script: |-
        ipsec_enabled = jelastic.env.control.GetNodeGroups("${env.envName}", session).object.filter(function (object) {
                          return object.name == "cp";
                        }).pop().ipsec
        return {"result": 0, "out": ipsec_enabled}

    - setGlobals:
        strongswanServiceStatus: ${response.out}

    - if ("${globals.strongswanServiceStatus}" == "enable"):
        - cmd[${this}]: |-
            systemctl enable strongswan.service
            systemctl start strongswan.service
          user: root

  stopJahia:
    cmd[${this}]: "service tomcat stop"
    user: root

  initJahiaDatabase:
    - log: "## Import DX schema in database"
    - cmd[${nodes.proc.first.id}]: cat $DATA_PATH/digital-factory-data/db/sql/schema/mysql/*.sql | mysql -h $DB_ENDPOINT -u$DB_USER -p$DB_PASSWORD -f jahia

  getMavenPath:
    - cmd [${nodes.proc.first.id}]: echo $(ls -d /opt/*maven*/bin/mvn)
    - setGlobals:
        jahia_cfg_mvnPath: ${response.out}

  installJahia:
    # Parameters:
    #   - jahiaVersion
    #   - __secret__rootpwd: Jahia root user password
    #   - __secret__toolspwd: Jahia Tools password
    - setSudoer: proc, cp
    - getLogEventScript: proc, cp

    - environment.nodegroup.ApplyData [proc, cp]:
        data:
          productName: dx
          productVersion: ${this.jahiaVersion}
    - initJahiaDatabase
    - log: "## Determine JDK version for good _JAVA_OPTIONS envvar"
    - cmd[proc, cp]: |-
        case "$($JAVA_HOME/bin/java -version 2>&1 | awk 'NR==1 {print gensub("(\"|_.*)", "", "g", $3)}')" in
          1.8*)
              j_opts='${globals.java_opts}'
              ;;
          *)
              j_opts='${globals.java_opts} -Xlog:gc:file=/opt/tomcat/logs/gc.log:time,uptime,level,pid,tid,tags'
              ;;
        esac
        sed -e '2isource /etc/profile' -e "s#\(^JAVA_OPTS=.*\)\(\"$\)#\1 ${j_opts}\2#" -i /opt/tomcat/conf/tomcat-env.sh
    - setJahiaPropertiesEnvvars
    - copyApp: proc, cp
    - setJahiaUserFeedbacksConfig
    - cmd[proc]: |-
        __secret__rootpwd="${this.__secret__rootpwd.toBase64()}"
        base64 -d <<< $__secret__rootpwd > $DATA_PATH/digital-factory-data/root.pwd
      user: tomcat
    - defineToolsPwd:
        __secret__toolspwd: ${this.__secret__toolspwd}
    - setToolsPwd: proc, cp
    - api: env.control.ExecDockerRunCmd
      nodeId: ${nodes.proc.first.id}
    - checkPatGroovyScriptExecution
    - startupJahiaHealthCheck: proc
    - env.control.ExecDockerRunCmd [${nodes.cp.join(id,)}]

  setJahiaPropertiesEnvvars:
    - log: "## Setting jahia.properties envvars"
    - getMavenPath
    - env.control.AddContainerEnvVars [cp, proc]:
      vars:
        jahia_cfg_expandImportedFilesOnDisk: ${globals.expandImportedFilesOnDisk}
        jahia_cfg_jahiaFileUploadMaxSize: ${globals.jahiaFileUploadMaxSize}
        jahia_cfg_imageService: ${globals.imageService}
        jahia_cfg_imageMagickPath: ${globals.jahiaImageMagickPath}
        jahia_cfg_mvnPath: ${globals.jahia_cfg_mvnPath}

  copyApp:
    - log: "## Copying Jahia app and setting its properties"
    - cmd[${this}]: |-
        [ "$_ROLE" == "Browsing" ] && sed -i "s#\(processingServer\s*=\).*#\1 false#g" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
        rm -rf $STACK_PATH/webapps/*
        #COPS-18 workaround, switch from loadbalance to sequential
        replace="sequential:"
        sed "s/loadbalance:/$replace/" -i /$DATA_PATH/jahia/tomcat/webapps/ROOT/META-INF/context.xml
        cp -rf $DATA_PATH/jahia/tomcat/webapps/* $STACK_PATH/webapps
        chown -R tomcat:tomcat $STACK_PATH/webapps
        tomcat_env=/opt/tomcat/conf/tomcat-env.sh
        short_name=$(echo ${_ROLE}.$HOSTNAME | sed -r 's/^([a-Z]+)\.[a-Z]+([0-9]+)-.+$/\1.\2/' | tr 'A-Z' 'a-z')
        sed -i "s|^cluster.node.serverId.*|cluster.node.serverId = $short_name|" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
        # the follwing will update or add if not present the jvmRoute property
        sed -i -n -e '/^\s*jahia.session.jvmRoute\s*=/!p' -e "\$ajahia.session.jvmRoute = $short_name" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
        grep -q '^JMX_OPTS=\-XX:+UseParallelGC$' ${tomcat_env} || sed -i "2i JMX_OPTS=\-XX:+UseParallelGC" ${tomcat_env}
        sed -i '/<!-- Access log processes all example./i \\t<!-- Remote IP Valve -->\n \t<Valve className="org.apache.catalina.valves.RemoteIpValve" protocolHeader="X-Forwarded-Proto" />\n' /opt/tomcat/conf/server.xml
        #Secure cookies from cross scripting
        indent="      " && printf "$indent<cookie-config>\n$indent$indent<secure>true</secure>\n$indent$indent<http-only>true</http-only>\n$indent</cookie-config>\n" > /tmp/cookies-config
        sed -i '/<session-config>/r /tmp/cookies-config' /opt/tomcat/conf/web.xml && rm /tmp/cookies-config
        # the following will update or add if not present these attributes: jvmRoute, maxPostSize, maxHttpHeaderSize
        xmlstarlet ed -P -L -S \
          -u "Server/Service/Engine/@jvmRoute" -v "$short_name" \
          -i "Server/Service/Engine[not(@jvmRoute)]" -t attr -n "jvmRoute" -v "$short_name" \
          -u "Server/Service/Connector[@port='80']/@maxPostSize" -v '${maxPostSize}' \
          -i "Server/Service/Connector[@port='80' and not(@maxPostSize)]" -t attr -n "maxPostSize" -v '${maxPostSize}' \
          -u "Server/Service/Connector[@port='80']/@maxHttpHeaderSize" -v '65536' \
          -i "Server/Service/Connector[@port='80' and not(@maxHttpHeaderSize)]" -t attr -n "maxHttpHeaderSize" -v '65536' \
          /opt/tomcat/conf/server.xml
        grep -q '^jahia_cfg_cluster_tcp_bindAddress=' ${tomcat_env} || sed -i '/TOMCAT_USER=/ a jahia_cfg_cluster_tcp_bindAddress=$(hostname -i)' ${tomcat_env}
        grep -q '^JAVA_OPTS.*-DmaxPostSize=' ${tomcat_env} || sed -i -E '/^JAVA_OPTS/ s/(.)$/ -DmaxPostSize=${tomcat_cfg_maxpostsize}\1/g' ${tomcat_env}
        grep -q '^JAVA_OPTS.*-XX:NativeMemoryTracking=' ${tomcat_env} || sed -i -E '/^JAVA_OPTS/ s/(.)$/ -XX:NativeMemoryTracking=summary\1/g' ${tomcat_env}
        # Datadog APM
        grep -q '^APM_OPTS=*' ${tomcat_env} || echo 'APM_OPTS="-Ddd.profiling.enabled=true -XX:FlightRecorderOptions=stackdepth=256 -Ddd.logs.injection=true -javaagent:/opt/tomcat/datadog/dd-java-agent.jar -Ddd.service=jahia -Ddd.env=${env.domain} -Ddd.trace.classes.exclude=org.jahia.modules.forms.dsl.*,org.jahia.modules.databaseConnector.dsl.*"' >>  ${tomcat_env}
        grep -q '^$DATADOG_APM_ENABLED*' ${tomcat_env} || echo '$DATADOG_APM_ENABLED && JAVA_OPTS+=" $APM_OPTS"' >> ${tomcat_env}

    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when installing jahia."

  defineToolsPwd:
    # Parameters:
    #   - __secret__toolspwd: Jahia Tools password
    - log: "## Now setting tools password"
    - setGlobalRepoRootUrl
    - cmd[proc]: |-
        if [ ! -f /usr/local/bin/reset-jahia-tools-manager-password.py ]; then
          curl -fLSso /usr/local/bin/reset-jahia-tools-manager-password.py ${globals.repoRootUrl}/assets/jahia/reset-jahia-tools-manager-password.py || exit 1
          chmod u+x /usr/local/bin/reset-jahia-tools-manager-password.py
        fi
        __secret__toolspwd="${this.__secret__toolspwd.toBase64()}"
        /usr/local/bin/reset-jahia-tools-manager-password.py $__secret__toolspwd $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties
      user: root
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when defining tools password."
    - cmd [proc]: awk '$1=="jahiaToolManagerPassword" {print $NF}' $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties
    - set:
        jahiaToolManagerPassword: ${response.out}
    - cmd [cp]: |-
        sed -i 's,^\s*\(jahiaToolManagerPassword\s*=\).*$,\1 ${this.jahiaToolManagerPassword},' $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties
    - env.control.AddContainerEnvVars [proc, cp]:
      vars:
        MANAGER_PASSWORD: ${this.jahiaToolManagerPassword}

  setToolsPwd:
    - cmd[${this}]: |-
         sed -i "s|^jahiaToolManagerPassword .*$|jahiaToolManagerPassword = $MANAGER_PASSWORD|" $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties

  setupDatadogAgentJahia:
    - log: "## Finalize Datadog agent setup on ${this}"
    - setGlobalRepoRootUrl
    - isAugSearchEnabled
    - getPatTokenAndKey
    - cmd[${this}]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        NODE_NAME=${HOSTNAME/-*}
        echo "hostname: ${_ROLE}.${NODE_NAME#node}" >> /etc/datadog-agent/datadog.yaml
        chmod 644 /opt/tomcat/logs/catalina.out
        mkdir /etc/datadog-agent/conf.d/jelastic.d /var/log/jelastic-packages
        chown tomcat:root /var/log/jelastic-packages
        chown dd-agent: /etc/datadog-agent/conf.d/jelastic.d
        curl -fLSso /etc/datadog-agent/conf.d/jelastic.d/conf.yaml ${globals.repoRootUrl}/assets/common/dd_agent_jelastic_package_conf.yml || exit 1
        # Configure AS check
        sed -i "s/jahia_root_token_placeholder/$__secret__pat_token/g" /etc/datadog-agent/conf.d/augmented_search.yaml-disabled
        if [ "${globals.isAugSearchEnabled}" == "true" ]; then
          mv /etc/datadog-agent/conf.d/augmented_search.yaml-disabled /etc/datadog-agent/conf.d/augmented_search.yaml
        fi
        /usr/local/bin/set_dd_tags.sh
        systemctl restart crond
        systemctl enable datadog-agent
      user: root

  startupJahiaHealthCheck:
    # Two arguments:
    #   - target: Mandatory, the target nodeId or nodeGroup. If the duration is not specified, the target
    #     can be passed as a parameter directly after the action name, e.g.: startupJahiaHealthCheck: <target>
    #   - duration: Optional, duration in seconds. Default value of 24 hours if not specified
    # The .print() call surrounded by simple quotes is the only working way I found to test if the variable exists
    - if ('${this.print()}' != ''):
        set:
          target: ${this}
    - else:
        set:
    - getPatTokenAndKey
    - cmd [${this.target}]: |-
        __secret__jahia_cfg_healthcheck_token=${globals.__secret__pat_token}
        if ! tomcat_pid=$(pgrep -u tomcat -f java); then
          echo "[ERROR] Tomcat process not found, please check." >&2
          exit 1
        fi

        if [ ! -f /var/log/tomcat/jahia.log ]; then
          echo "[ERROR] Jahia log file not found, it seems there is a problem with tomcat instance, please check." >&2
          exit 2
        fi

        startup_line=$(grep -n "s t a r t i n g" /opt/tomcat/logs/catalina.out | tail -n1 | cut -d":" -f1)
        timeout=$(date --date="+$HEALTHCHECK_DURATION minutes" +%s)
        hc_url="http://127.0.0.1:8080/modules/healthcheck?severity=critical"

        # Number of minutes allowed for healthcheck to be completed once tomcat startup is finished
        jahia_running_timeout=5

        while [ $(date +%s) -lt $timeout ]; do
          # First we test if Jahia is up with a curl request.
          if curl_resp=$(curl -f -s -m 1 "$hc_url" -H "authorization: APIToken $__secret__jahia_cfg_healthcheck_token"); then
            status=$(echo $curl_resp | jq -r ".status.health")
            if [ "$status" = "GREEN" ] || [ "$status" = "YELLOW" ]; then
              exit 0
            fi
          fi

          # If it isn't, we first check tomcat process status
          if ! ps --pid $tomcat_pid > /dev/null; then
            echo "[ERROR] Tomcat process no more running, please check." >&2
            exit 3
          fi
          # Then we check Jahia startup status, all
          tail -n +${startup_line} /opt/tomcat/logs/catalina.out | grep -q "Server startup in"
          if [ $? -eq 0 ]; then
            if [ $jahia_running_timeout -eq 0 ]; then
              echo "[ERROR] Tomcat startup is finished but healthcheck failed, please check." >&2
              exit 4
            fi
            ((jahia_running_timeout-=1))
          fi

          sleep 60
        done

        echo "[ERROR] Timeout, the Tomcat process is still running but Jahia is not started yet" >&2
        exit 5

  checkJahiaHealth:
    - getPatTokenAndKey
    - cmd [${this}]: |-
        __secret__jahia_cfg_healthcheck_token=${globals.__secret__pat_token}
        if ! tomcat_pid=$(pgrep -u tomcat -f java); then
          echo "[ERROR] Tomcat process not found, please check" >&2
          exit 1
        fi

        hc_url="http://127.0.0.1:8080/modules/healthcheck?severity=critical"

        if curl_resp=$(curl -f -s -m 1 "$hc_url" -H "authorization: APIToken $__secret__jahia_cfg_healthcheck_token"); then
          status=$(echo $curl_resp | jq -r ".status.health")
          if [ "$status" = "GREEN" ] || [ "$status" = "YELLOW" ]; then
            exit 0
          fi
        fi
        echo "[ERROR] Healthcheck result different from GREEN or YELLOW, exiting" 1>&2 && exit 1

  checkJahiaDatadogCustomChecks:
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: proxysql
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: jahia_node_not_in_haproxy_pool
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: strongswan_connections_status
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: augmented_search

  saveApplicationcontextFilesBeforeRedeploy:
    cmd[${this}]: |-
      mkdir /opt/tomcat/conf/digital-factory-config/jahia/applicationcontext-files.tmp
      mv /opt/tomcat/conf/digital-factory-config/jahia/applicationcontext*.xml /opt/tomcat/conf/digital-factory-config/jahia/applicationcontext-files.tmp/

  restoreApplicationcontextFilesAfterRedeploy:
    cmd[${this}]: |-
      mv /opt/tomcat/conf/digital-factory-config/jahia/applicationcontext-files.tmp/* /opt/tomcat/conf/digital-factory-config/jahia/
      rmdir /opt/tomcat/conf/digital-factory-config/jahia/applicationcontext-files.tmp

  deleteEnvLinkJahia:
    # Parameters:
    #   - jCustomerEnv: Jcustomer env name in the env link of Jahia
    # Returns:
    #   - ${response.link_removed}: true or false (true if Jahia env is removed from envLink of Jcustomer)
    - script: |-
        const envName = "${env.envName}";
        const jCustomerEnv = "${this.jCustomerEnv}";
        envsLinked = jelastic.env.control.GetNodeGroups(jCustomerEnv, session).object.filter(function (object) {
                                return object.name == "cp";
                              }).pop().envLink;
        if (envsLinked.indexOf(envName) == -1) {
          return {"result": 0, "link_removed": false, "out": envName + " not in envLink of " + jCustomerEnv};
        }

        // envLink can contain multiple Jahia envs on jCustomer side separated by a comma
        if (envsLinked.indexOf(",") != -1) {
          envsLinkedArr = envsLinked.split(",");
          envsLinkedArr.splice(envsLinkedArr.indexOf(envName), 1);
          newEnvLink = String(envsLinkedArr);
        } else {
          newEnvLink = null;
        }
        resp = jelastic.env.nodegroup.ApplyData(jCustomerEnv, session, nodeGroup='cp', data={'envLink': newEnvLink});
        return {"result": 0, "link_removed": true, "out": envName + " removed from envLink of " + jCustomerEnv};

  removeKibanaDashboardAccountsAndSpace:
    # Parameters:
    #   - jCustomerEnv: Jcustomer env name in the env link of Jahia
    - set:
        dashboardRoleAndAccountName: ${env.envName}-kibana-dashboard
        adminRoleAndAccountName: ${env.envName}-kibana-admin
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/delete-kibana-role.yml",
              envName: "${this.jCustomerEnv}",
              settings: {
                'roleName': '${this.dashboardRoleAndAccountName}',
              }
            }
          );
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/delete-elasticsearch-account.yml",
              envName: "${this.jCustomerEnv:}",
              settings: {
                'accountName': '${this.dashboardRoleAndAccountName}',
              }
            }
          );
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/delete-elasticsearch-account.yml",
              envName: "${this.jCustomerEnv:}",
              settings: {
                'accountName': '${this.adminRoleAndAccountName}',
              }
            }
          );
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/delete-kibana-space.yml",
              envName: "${this.jCustomerEnv}",
              settings: {
                'spaceName': '${this.dashboardRoleAndAccountName}',
              }
            }
          );


  isFullReadonlyEnabled:
    - cmd[proc]: |-
        RO_ON=$(ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR full-read-only | grep -e Current -e local | grep ON)
        if [ "$RO_ON" == "" ]; then
          echo false
        else
          echo true
        fi
    - setGlobals:
        RO: "${response.out}"

  switchFullReadonly:
    - log: "switch full read mode to ${this.fullreadmode} on nodegroup ${this.group}"
    - cmd[${this.group}]: |-
          ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR full-read-only ${this.fullreadmode}

  switchReadonly:
    - log: "switch read-only mode to ${this.readmode} on nodegroup ${this.group}"
    - cmd[${this.group}]: |-
        # Don't know why but running this command in one line fails half of the time so the output is captured and displayed so we have two lines.
        res=$(ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR read-only ${this.readmode})
        echo $res

  enableKarafLogin:
    - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
      script: |-
          try {
            var resp = JSON.parse(isKarafLoginEnabled)["${this}"]
          } catch(error) {
            var resp = false
          }
          return {"result": 0, "resp": resp}
    - if(${response.resp}):
        - log: "karaf login is already enabled, nothing to do"
    - else:
        - log: "Activate karaf's ssh login on ${this}"
        - cmd[${this}]: |-
            # Clear everything and enable karaf login
            [ -f /tmp/abricot ] && rm /tmp/abricot
            [ -f /tmp/abricot.pub  ] && rm /tmp/abricot.pub
            ssh-keygen -t rsa -f /tmp/abricot -P ""
            awk '{printf "abricot:%s,_g_:admingroup\n",$2}' /tmp/abricot.pub >> /data/digital-factory-data/karaf/etc/keys.properties
            sed 's,\(sshRealm\s*=\s*\)jahia,\1karaf,' -i /data/digital-factory-data/karaf/etc/org.apache.karaf.shell.cfg
            i=1
            it=66
            until (ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR full-read-only); do
              echo "karaf ssh login not updated yet (iteration $i/$it)"
              if [ $i -ge $it ]; then
                echo "Too long to start, something is wrong here... EXITING"
                exit 1
              fi
              ((i++))
              sleep 1
            done
        - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
          script: |-
            try {
              var isEnable = JSON.parse(isKarafLoginEnabled)
            } catch(error) {
              var isEnable = {}
            } finally {
              isEnable["${this}"] = true
            }
            return {"result": 0, "isEnable": isEnable}
        - setGlobals:
            isKarafLoginEnabled: ${response.isEnable}
            karafConsole: "ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR"

  disableKarafLogin:
    - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
      script: |-
          try {
            var resp = JSON.parse(isKarafLoginEnabled)["${this}"]
          } catch(error) {
            var resp = false
          }
          return {"result": 0, "resp": resp}
    - if(! ${response.resp}):
        - log: "karaf login is already disabled, nothing to do"
    - else:
        - log: "Disable karaf's ssh login on ${this}"
        - cmd[${this}]: |-
            [ -f /tmp/abricot  ] && rm /tmp/abricot
            [ -f /tmp/abricot.pub  ] && rm /tmp/abricot.pub
            sed '/^abricot:/d' -i /data/digital-factory-data/karaf/etc/keys.properties
            sed 's,\(sshRealm\s*=\s*\)karaf,\1jahia,' -i /data/digital-factory-data/karaf/etc/org.apache.karaf.shell.cfg
        - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
          script: |-
            try {
              var isEnable = JSON.parse(isKarafLoginEnabled)
            } catch(error) {
              var isEnable = {}
            } finally {
              isEnable["${this}"] = false
            }
            return {"result": 0, "isEnable": isEnable}
        - setGlobals:
            isKarafLoginEnabled: ${response.isEnable}

  enableReadOnlyOnCluster:
    - enableKarafLogin: "proc, cp"
    - switchReadonly:
        group: "proc, cp"
        readmode: "ON"
    - disableKarafLogin: "proc, cp"

  disableReadOnlyOnCluster:
    - enableKarafLogin: "proc, cp"
    - switchReadonly:
        group: "proc, cp"
        readmode: "OFF"
    - disableKarafLogin: "proc, cp"

  enableFullReadOnlyOnCluster:
    - getJahiaVersion

    - enableKarafLogin: proc
    - isFullReadonlyEnabled

    - if(!${globals.RO}):
        - switchFullReadonly:
            group: "proc"
            fullreadmode: "ON"

        - isVersionStrictlyLower:
            a: ${globals.jahiaVersion}
            b: 7.3.3.0
            res: enableVersionLowerThan7330

        - if( ${globals.enableVersionLowerThan7330} ):
            - enableKarafLogin: cp
            - switchFullReadonly:
                group: "cp"
                fullreadmode: "ON"

  disableFullReadOnlyOnCluster:
    - getJahiaVersion
    - isFullReadonlyEnabled

    - if(${globals.RO}):
        - switchFullReadonly:
            group: "proc"
            fullreadmode: "OFF"
        - disableKarafLogin: proc

        - isVersionStrictlyLower:
            a: ${globals.jahiaVersion}
            b: 7.3.3.0
            res: disableVersionLowerThan7330

        - if( ${globals.disableVersionLowerThan7330} ):
            - switchFullReadonly:
                group: "cp"
                fullreadmode: "OFF"
            - disableKarafLogin: cp

  getJahiaVersion:
  # The placeholder ${nodes.proc.first.customitem.nodeVersion} doesn't return the correct value during an upgrade
  # and thus jelastic API is more reliable in this case.
    - log: "Get jahia version"
    - script: |-
        const envName = "${env.envName}";
        resp = jelastic.env.control.GetEnvInfo(envName, session)
        for (i = 0, g = resp.nodes; i < g.length; i++) {
          if (g[i].nodeGroup == "proc") {
            nodeVersion = g[i].customitem.nodeVersion
            return {
              "result": 0,
              "onAfterReturn": {
                "setGlobals": {
                  "jahiaVersion": nodeVersion
                }
              }
            }
          }
        }
        return {"result": 1, errOut: "Can't get Jahia version"}
    - log: "Jahia is v${globals.jahiaVersion}"

  installOrUpgradeModule:
    # Installs and starts a module with the specified version. If the module is already installed, several use cases:
    # - if it is not running, then the specified version is installed and started
    # - if it is running with an older version, then the specified version is installed and started
    # - if it is running with the same version or a more recent one, then nothing is done, to prevent downgrade
    # Last step is to clean the module by uninstalling stopped versions to only keep the running (and desired) one
    #
    # Parameters:
    # - moduleSymname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    # - moduleVersion: the version of the module to install
    # - moduleGroupId: group id of the artifact
    # - moduleRepository: repository that the artifact is contained in Nexus
    - set:
        moduleInstalled: true
    - checkModule:
        moduleSymname: ${this.moduleSymname}
    - if ("${globals.moduleState}" == "uninstalled"):
        - installModule:
            moduleSymname: ${this.moduleSymname}
            moduleVersion: ${this.moduleVersion}
            moduleGroupId: ${this.moduleGroupId}
            moduleRepository: ${this.moduleRepository}
            startModule: true
    - else:
        - if ("${globals.moduleState}" == "installed"):
            - installModule:
                moduleSymname: ${this.moduleSymname}
                moduleVersion: ${this.moduleVersion}
                moduleGroupId: ${this.moduleGroupId}
                moduleRepository: ${this.moduleRepository}
                startModule: true
        - if ("${globals.moduleState}" == "started"):
            - isVersionStrictlyHigher:
                a: "${this.moduleVersion}"
                b: "${globals.runningVersion}"
                res: needsInstall
            - if (${globals.needsInstall}):
                - installModule:
                    moduleSymname: ${this.moduleSymname}
                    moduleVersion: ${this.moduleVersion}
                    moduleGroupId: ${this.moduleGroupId}
                    moduleRepository: ${this.moduleRepository}
                    startModule: true
            # If the module is already running with the desired version or a more recent one, we don't need to check the status right after
            - else:
                # Prints a warning if the module is running with a more recent version only. If same version, nothing is wrong so no warning
                - if ("${globals.runningVersion}" != "${this.moduleVersion}"):
                    - log: "WARNING: ${this.moduleSymname} is already running with a more recent version (${globals.runningVersion}), version ${this.moduleVersion} won't be installed"
                - set:
                    moduleInstalled: false
    - if (${this.moduleInstalled}):
        - checkModule:
            moduleSymname: ${this.moduleSymname}
        - if ("${globals.moduleState}" != "started") || ("${globals.runningVersion}" != "${this.moduleVersion}"):
            - log: ${this.moduleSymname} is either not running, or running with a different version than the desired one
            - return:
                type: error
                message: "An error occurred during module upgrade/installation."
    - uninstallStoppedVersionsOfModule:
        moduleSymname: ${this.moduleSymname}
        moduleVersion: ${this.moduleVersion}

  checkModule:
    # Checks the state of a module.
    # First we check the state of the module, uninstalled, installed or started. Then, if installed or started,
    # we check the version: most recent version installed if module is not running, or running version otherwise.
    #
    # Parameters:
    # - moduleSymname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    # Returns:
    # - globals.moduleState:
    #   - "started" if the module is running
    #   - "installed" if the module is installed but not running
    #   - "uninstalled" if the module is not installed
    # - globals.mostRecentInstalledVersion: the most recent version installed
    # - globals.runningVersion: the version running (if any)
    # - globals.installedVersionsCount: the number of installed versions
    - setGlobals:  # re-initialise globals to prevent successive calls to this action from overlapping
        moduleState: ""
        runningVersion: ""
        mostRecentInstalledVersion: ""
        installedVersionsCount: 0
    - getPatTokenAndKey
    - cmd [proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" "localhost/modules/api/bundles/${this.moduleSymname}/*/_localInfo")
        case "$(jq -r ". | length" <<< $resp)" in
          "0") # Means the module is not installed
            echo "uninstalled"
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *)
            if jq -r 'to_entries[] | "\(.key);\(.value | .moduleState)"' <<< $resp | grep -q STARTED; then
              echo "started"
            else
              echo "installed"
            fi
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module verification."
    - else:
        - log: ${this.moduleSymname} is ${response.out}
        - setGlobals:
            moduleState: ${response.out}
    - if ("${globals.moduleState}" == "started") || ("${globals.moduleState}" == "installed"):
        - cmd [proc]: |-
            __secret__pat_token="${globals.__secret__pat_token}"
            resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" "localhost/modules/api/bundles/${this.moduleSymname}/*/_localInfo")
            module_started=$(jq -r 'to_entries[] | "\(.key);\(.value | .moduleState)"' <<< $resp | grep STARTED)
            # If module is started, then we get the running version
            running_version=""
            if [ $? -eq 0 ]; then
              running_version=$(echo $module_started | cut -d';' -f1 | awk -F'/' '{print $NF}')
            fi
            most_recent_installed_version=$(jq -r "keys[]" <<< $resp | awk -F'/' '{print $NF}' | sort -nr | head -1)
            installed_versions_count=$(jq -r "keys | length" <<< $resp)
            echo "{ \
                'runningVersion': '$running_version', \
                'mostRecentInstalledVersion': '$most_recent_installed_version', \
                'installedVersionsCount': '$installed_versions_count'\
              }"
        - script: |-
            const resp = ${response.out.toJSON()}
            return {
              "result": 0,
              "onAfterReturn": {
                setGlobals: {
                  "runningVersion": resp.runningVersion,
                  "mostRecentInstalledVersion": resp.mostRecentInstalledVersion,
                  "installedVersionsCount": resp.installedVersionsCount
                }
              }
            };

  checkVersionOfModule:
    # Checks the state of a module for a specific version: uninstalled, installed or started.
    #
    # Parameters:
    # - moduleSymname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    # - moduleVersion: the version of the module to check
    # Returns:
    # - globals.moduleVersionState:
    #   - "started" if the specified version of the module is running
    #   - "installed" if the specified version of the module is installed but not running
    #   - "uninstalled" if the specified version of the module is not installed
    - getPatTokenAndKey
    - cmd [proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" "localhost/modules/api/bundles/${this.moduleSymname}/${this.moduleVersion}/_localInfo")
        case "$(jq -r .moduleState <<< $resp)" in
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          STARTED) # Means the module is running
            echo "started"
            ;;
          null|UNINSTALLED) # null is in case a 404 (but still JSON) is returned (normal behavior)
            echo "uninstalled"
            ;;
          *)
            echo "installed"
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module verification."
    - else:
        - log: ${this.moduleSymname}/${this.moduleVersion} is ${response.out}
        - setGlobals:
                moduleVersionState: ${response.out}

  installModule:
    # Downloads a module jar file and installs it. The module can also be started at the same time.
    # If the module is already installed, the installation is skipped, but if the "startModule" parameter is set to true,
    # then the specified version of the module is started.
    #
    # Parameters:
    #   - moduleSymname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - moduleVersion: the version of the module to install
    #   - moduleGroupId: group id of the artifact in Nexus
    #   - moduleRepository: repository that the artifact is contained in Nexus
    #   - startModule (optional): if the module should be started or not, true or false. Default: false
    - checkVersionOfModule:
        moduleSymname: ${this.moduleSymname}
        moduleVersion: ${this.moduleVersion}
    - if ("${globals.moduleVersionState}" == "uninstalled"):
      - set:
          modulesUrl: https://devtools.jahia.com/nexus/service/local/artifact/maven/content
      - if ('${this.startModule.print()}' == ''):
          set:
            startModule: "false"
      - getVaultData
      - vaultSecretReadAllKeysB64:
          secretPath: "paas/envs-common/nexus"
      - script: |-
          import java.util.Base64;

          __secret__vaultResponseBase64 = "${globals.__secret__vaultSecretData}";
          vaultResponse = JSON.parse(java.lang.String(java.util.Base64.getDecoder().decode(__secret__vaultResponseBase64)))
          nexusCreds = vaultResponse.login + ":" + vaultResponse.password
          credsBytes = (new java.lang.String(nexusCreds)).getBytes("UTF-8");
          encodedNexusCreds = Base64.getEncoder().encodeToString(credsBytes);
          return {
            "result": 0,
            "onAfterReturn": {
              set: {
                "__secret__nexusCreds": encodedNexusCreds
              }
            }
          };
      - getPatTokenAndKey
      - log: Installing ${this.moduleSymname}/${this.moduleVersion}
      - cmd [proc]: |-
          __secret__nexus_creds="${this.__secret__nexusCreds}"
          __secret__pat_token="${globals.__secret__pat_token}"

          tmp_dir=$(mktemp -d)
          local_jar_file=$tmp_dir/${this.moduleSymname}-${this.moduleVersion}.jar
          curl -fLSso $local_jar_file "${this.modulesUrl}" -G \
            -H "Authorization: Basic $__secret__nexus_creds" \
            -d "g=${this.moduleGroupId}" \
            -d "r=${this.moduleRepository}" \
            -d "a=${this.moduleSymname}" \
            -d "v=${this.moduleVersion}" >&2
          if [ $? -ne 0 ]; then
            echo "error"
            rm -rf $tmp_dir
            exit 0
          fi
          resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" -XPOST \
                  --form bundle=@$local_jar_file \
                  --form start=${this.startModule} \
                  localhost/modules/api/bundles)
          case "$(jq -r .bundleInfos <<< $resp)" in
            "null") # If install failed, there is no bundleInfos attribute in the JSON response
              echo "error"
              jq -r .message <<< $resp >&2
              ;;
            "") # if response is not JSON, for instance 401 unauthorized
              echo "error"
              echo $resp >&2
              ;;
            *) # Otherwise it means the module was installed, nothing to do
              ;;
          esac
          rm -rf $tmp_dir
      - if ("${response.out}" == "error"):
          - return:
              type: error
              message: "An error occurred during module installation."
      - log: ${this.moduleSymname}/${this.moduleVersion} has been installed
    - elif ("${globals.moduleVersionState}" == "installed"):
        - log: ${this.moduleSymname}/${this.moduleVersion} is already installed, skipping the installation
        - if (${this.startModule}):
            - startModule:
                moduleSymname: ${this.moduleSymname}
                moduleVersion: ${this.moduleVersion}
    - else:
        - log: ${this.moduleSymname}/${this.moduleVersion} is already running, nothing to do

  stopModule:
    # Stops the running version of a module.
    #
    # Parameters:
    #   - moduleSymname: the symbolic name of the module to stop (for instance "distributed-sessions")
    - getPatTokenAndKey
    - log: Stopping ${this.moduleSymname}
    - cmd [proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" -XPOST -d "" \
                 "localhost/modules/api/bundles/${this.moduleSymname}/_stop")
        case "$(jq -r .bundleInfos <<< $resp)" in
          "null") # If stop failed, there is no bundleInfos attribute in the JSON response
            echo "error"
            jq -r .message <<< $resp >&2
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module was stopped, nothing to do
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module stop."
    - log: ${this.moduleSymname}/${this.moduleVersion} has been stopped


  startModule:
    # Starts the specified version of a module.
    #
    # Parameters:
    #   - moduleSymname: the symbolic name of the module to start (for instance "distributed-sessions")
    #   - moduleVersion: the version of the module to install
    - getPatTokenAndKey
    - log: Starting ${this.moduleSymname}/${this.moduleVersion}
    - cmd [proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" -XPOST -d "" \
                 "localhost/modules/api/bundles/${this.moduleSymname}/${this.moduleVersion}/_start")
        case "$(jq -r .bundleInfos <<< $resp)" in
          "null") # If install failed, there is no bundleInfos attribute in the JSON response
            echo "error"
            jq -r .message <<< $resp >&2
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module was started, nothing to do
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module startup."
    - log: ${this.moduleSymname}/${this.moduleVersion} has been started

  uninstallModuleVersion:
    # Uninstalls the specified version of a module.
    #
    # Parameters:
    #   - moduleSymname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - moduleVersion: the version of the module to install
    - getPatTokenAndKey
    - log: Uninstalling ${this.moduleSymname}/${this.moduleVersion}
    - cmd [proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" -XPOST -d "" \
              "localhost/modules/api/bundles/${this.moduleSymname}/${this.moduleVersion}/_uninstall")
        case "$(jq -r .bundleInfos <<< $resp)" in
          "null") # If uninstall failed, there is no bundleInfos attribute in the JSON response
            echo "error"
            jq -r .message <<< $resp >&2
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module was uninstalled, nothing to do
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module uninstall."
    - log: Version ${this.moduleVersion} of ${this.moduleSymname} module uninstalled

  uninstallStoppedVersionsOfModule:
    # Uninstalls all the stopped versions of a module. If no version of the module is running, the module
    # will be completely uninstalled. If the module is not installed, nothing is done.
    #
    # Parameters:
    #   - moduleSymname: the module to clean
    - getPatTokenAndKey
    - log: Uninstalling stopped versions of ${this.moduleSymname} module
    - cmd [proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" "localhost/modules/api/bundles/${this.moduleSymname}/*/_localInfo")
        case "$(jq -r ". | length" <<< $resp)" in
          "0") # Means the module is not installed, nothing to do
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *)
            jq -r 'to_entries[] | "\(.key);\(.value | .moduleState)"' <<<$resp | grep -v STARTED | cut -d';' -f1 | awk -F'/' '{print $NF}' | tr "\n" ";" | sed 's/.$//'
            ;;
        esac
    - if ("${response.out}" == ""):
        log: ${this.moduleSymname} module doesn't have any stopped version, nothing to do
    - elif ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module installation."
    - else:
        - log: "Versions to delete for ${this.moduleSymname} module: ${response.out}"
        - script: |-
            return {"result": 0, "versions": "${response.out}".split(";")}
        - forEach(response.versions):
            - uninstallModuleVersion:
                moduleSymname: ${this.moduleSymname}
                moduleVersion: ${@i}
        - log: Stopped versions of ${this.moduleSymname} module uninstalled

  uninstallModule:
    # Uninstalls all the versions of a module If the module is not installed, nothing is done.
    #
    # Parameters:
    #   - moduleSymname: the module to clean
    - getPatTokenAndKey
    - log: Uninstalling all versions of ${this.moduleSymname} module
    - cmd[proc]: |-
        __secret__pat_token="${globals.__secret__pat_token}"
        resp=$(curl -SsH "Authorization: APIToken $__secret__pat_token" "localhost/modules/api/bundles/${this.moduleSymname}/*/_localInfo")
        case "$(jq -r ". | length" <<< $resp)" in
          "0") # Means the module is not installed
            echo "not installed"
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *)
            jq -r "keys[]" <<< $resp | awk -F'/' '{print $NF}' | sort -nr | tr "\n" ";" | sed 's/.$//'
            ;;
        esac
    - if ("${response.out}" == "not installed"):
        log: ${this.moduleSymname} module is not installed, nothing to do
    - elif ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module uninstall."
    - else:
        - log: "Versions to delete for ${this.moduleSymname} module: ${response.out}"
        - script: |-
            return {"result": 0, "versions": "${response.out}".split(";")}
        - forEach(response.versions):
            - uninstallModuleVersion:
                moduleSymname: ${this.moduleSymname}
                moduleVersion: ${@i}
        - log: ${this.moduleSymname} module completely uninstalled

  triggerAugSearchFullReindex:
    # Parameters:
    #   asynchronous: true to not wait for the end of the fullReindex, false otherwise. Default true
    cmd[proc]: |-
        __secret__API_TOKEN="${globals.__secret__pat_token}"
        curl -XPOST \
          http://localhost:8080/modules/graphql \
          -H "Authorization: APIToken $__secret__API_TOKEN" \
          -H "Content-Type: application/json" \
          -H "Origin: http://localhost:8080" \
          -d '{"query":"mutation {admin {search {startIndex {jobs {id status project {siteKey} } } } } } "}'

        if [ "${this.asynchronous:true}" == "true" ]; then
          exit 0
        fi

        check_indexation_state() {
          res=$(curl -s -XPOST \
          http://localhost:8080/modules/graphql \
          -H "Authorization: APIToken $__secret__API_TOKEN" \
          -H 'Content-Type: application/json' \
          -H 'Origin: http://localhost:8080' \
          -d '{"query":"{admin {search {listSites {sites {indexationStatus siteKey} } } } } "}')
          echo $res | jq -r '.data.admin.search.listSites.sites | .[] | select(.indexationStatus!="COMPLETED")'
        }

        check=$(check_indexation_state)
        while [ ! -z "$check" ]; do
          sleep 30
          check=$(check_indexation_state)

          # As the operation can take several hours, it's impossible to set a timeout value
          # The manual and "clean" way to abort the package is to create the /tmp/stopWaitingForReindexEnd file.
          if [ -f "/tmp/stopWaitingForReindexEnd" ]; then
            echo "Force quit"
            exit 1
          fi
        done

  setJahiaUserFeedbacksConfig:
    - getJahiaVersion
    - isVersionHigherOrEqual:
        a: ${globals.jahiaVersion}
        b: 8.0.0.0
        res: jahia8
    - if (${globals.jahia8}):
        - script: |-
            const envName = "${env.envName}";
            orgName = jelastic.env.control.GetNodeGroups(envName, session).object.filter(function (object) {
                                        return object.name == "cp";}).pop().ORGANIZATION_NAME;
            return {
              "result": 0,
              "onAfterReturn": {
                "set": {
                  "organizationName": orgName
                }
              }
            }
        - cmd[proc]: |-
            config_file="/data/digital-factory-data/karaf/etc/org.jahia.services.env.cfg"
            organization_name="${this.organizationName}"
            env_name="${env.envName}"
            if [ ! -f $config_file ]; then
              touch $config_file
              echo "org.jahia.services.env.organization=$organization_name" >> $config_file
              echo "org.jahia.services.env.env_name=$env_name" >> $config_file
            else
              if ( ! grep -q "organization=$organization_name" $config_file ) || ( grep -qc "organization=$organization_name" $config_file | awk -F: '$NF+0 > 1' ); then
                sed -i '/.*organization=.*/d' $config_file
                echo "org.jahia.services.env.organization=$organization_name" >> $config_file
              fi
              if ( ! grep -q "env_name=$env_name" $config_file ) || ( grep -qc "env_name=$env_name" $config_file | awk -F: '$NF+0 > 1' ); then
                sed -i '/.*env_name=.*/d' $config_file
                echo "org.jahia.services.env.env_name=$env_name" >> $config_file
              fi
            fi


  ####################
  # proxysql related #
  ####################
  setupProxysqlCluster:
    - cmd[cp, proc]: |-
          ${globals.proxysql_cli} -e "DELETE FROM proxysql_servers"
    - foreach (nodes.cp):
        - cmd[cp, proc]: |-
            ${globals.proxysql_cli} -e "INSERT INTO proxysql_servers (hostname,port,weight,comment) VALUES ('node${@i.id}-${env.domain}',6032,0,'browsing_$((${@}+1))')"
    - cmd [cp, proc]: |-
        ${globals.proxysql_cli} -e "INSERT INTO proxysql_servers (hostname,port,weight,comment) VALUES ('node${nodes.proc.first.id}-${env.domain}',6032,0,'processing')"
        ${globals.proxysql_cli} -e "LOAD PROXYSQL SERVERS TO RUNTIME"
        ${globals.proxysql_cli} -e "SAVE PROXYSQL SERVERS TO DISK"
    - cmd [cp, proc]: |-
        i=60
        sql="select count(*) from stats_proxysql_servers_metrics where Uptime_s = 0"
        while ! sleep 1 && ${globals.proxysql_cli} -e "$sql" | grep -s 0; do
          ((i--))
          if [ $i -eq 0 ]; then
            echo "[ERROR] ProxySQL cluster is not healthy" 1>&2
            exit 1
          fi
        done
    - if (nodes.sqldb.length == 1):
        configureProxysqlForSingleDBNode

  configureProxysqlForSingleDBNode:
    cmd[cp, proc]: |-
      ${globals.proxysql_cli} -e "DELETE FROM mysql_servers WHERE hostgroup_id!=2;"
      ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections) VALUES (2,'galera_1',3306, 50)"
      ${globals.proxysql_cli} -e "UPDATE mysql_galera_hostgroups SET active=0;"
      ${globals.proxysql_cli} -e "LOAD MYSQL SERVERS TO RUNTIME;"
      ${globals.proxysql_cli} -e "SAVE MYSQL SERVERS TO DISK;"

  setupMysqlServers:
    - cmd[proc]: |-
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections) VALUES (2,'galera_1',3306, 50)"
    - if (nodes.sqldb.length > 1):
        - cmd[proc]: |-
            ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections) VALUES (2,'galera_2',3306, 50)"
            ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_3',3306, 50, 1000)"
    - cmd[proc]: |-
        ${globals.proxysql_cli} -e "LOAD MYSQL SERVERS TO RUNTIME"
        ${globals.proxysql_cli} -e "SAVE MYSQL SERVERS TO DISK"

  setupMonitorUser:
    - cmd[sqldb]: |-
        mysql -e "CREATE USER IF NOT EXISTS 'proxysql'@'%' IDENTIFIED BY 'monitorpassword'"
        mysql -e "GRANT SELECT on sys.* TO 'proxysql'@'%'"
        mysql -e "GRANT SELECT on performance_schema.* TO 'proxysql'@'%'"
        mysql -e "GRANT  PROCESS, REPLICATION CLIENT ON *.* TO 'proxysql'@'%'"

  enableBackendMonitor:
    - cmd[cp, proc]: |-
        ${globals.proxysql_cli} -e "UPDATE global_variables SET variable_value='true' WHERE variable_name='mysql-monitor_enabled'"
        ${globals.proxysql_cli} -e "LOAD MYSQL VARIABLES TO RUNTIME"
        ${globals.proxysql_cli} -e "SAVE MYSQL VARIABLES TO DISK"

  finishProxysqlInstall:
    - setupMonitorUser
    - enableBackendMonitor
    - if (nodes.sqldb.length > 1):
        - setupMysqlServers
    - else:
        - disableDatadogCustomChecks
    - setupProxysqlCluster

  refreshProxysqlInstancesList:
    - setupProxysqlCluster

  proxysqlSetMariadbBackendStatus:
    - cmd[cp, proc]: |-
        ${globals.proxysql_cli} -e "UPDATE mysql_servers SET status='${this.newStatus}' WHERE hostname='${this.targetHost}';"

  getGaleraMaster:
    # Return:
    #   - galeraMasterIndex
    - cmd[proc]: |-
        ${globals.proxysql_cli} -BNe "select DISTINCT hostname from runtime_mysql_servers where weight = 1000"
    - setGlobals:
        - galeraMasterIndex: ${response.out}

  proxysqlSwitchMaster:
    # Parameter:
    #   - target: galera number (1,2,3)
    - cmd[proc, cp]: |-
        # Check that the future master node is online
        res=$(${globals.proxysql_cli} -BNe "select * from runtime_mysql_servers where hostname='galera_${this.target}' and hostgroup_id=2 and status='ONLINE';")
        if [ -z "$res" ];then
          echo "The new masterNode is not online in proxySQL configuration" >> /var/log/jelastic-packages/proxySqlSwitchMaster.log
          exit 0
        fi

    - cmd[proc, cp]: |-
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_1',3306, 50, 1);"
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_2',3306, 50, 1);"
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_3',3306, 50, 1);"
        ${globals.proxysql_cli} -e "update mysql_servers set weight=1000 where hostname='galera_${this.target}';"
        ${globals.proxysql_cli} -e "LOAD MYSQL SERVERS TO RUNTIME;"
        ${globals.proxysql_cli} -e "SAVE MYSQL SERVERS TO DISK"
        sleep 15

    - cmd[proc, cp]: |-
        # Check that there is only a single node with a weight of 1000
        res=$(${globals.proxysql_cli} -BNe "select * from runtime_mysql_servers where weight=1000 group by hostname;" | wc -l)
        if [ $res -lt 1 ];then
          echo "There is no master node with a weight of 1000 in proxysql runtime configuration" >> /var/log/jelastic-packages/proxySqlSwitchMaster.log
          exit 1
        elif [ $res -gt 1 ]; then
          echo "There is more than one master node with a weight of 1000 in proxysql runtime configuration" >> /var/log/jelastic-packages/proxySqlSwitchMaster.log
          exit 1
        fi

    - cmd[sqldb]: |-
        my_ip=$(grep $(hostname) /etc/hosts | awk '{print $1}')
        my_node_name_index=$(awk -v my_ip="$my_ip galera" '$0 ~my_ip {print $2}' /etc/hosts)
        if [[ "$my_node_name_index" == "galera_${this.target}" ]]; then
          exit 0
        fi
        timeout=1200 # wait for 1200s
        tries=0
        request="select COUNT(*) from INFORMATION_SCHEMA.PROCESSLIST where db='jahia' and user like 'jahia-db-%'"
        while [[ $(mysql -BNe "$request") -gt 0 ]]; do
          if [[ $tries -ge $timeout ]]; then
            echo "There are still open connections on $my_node_name_index"
            exit 1
          fi
          tries=`expr $tries + 10`
          sleep 10
        done

  disableDatadogCustomChecks:
    - cmd[cp, proc]: |-
        p="/etc/datadog-agent/conf.d"
        for check in proxysql_backend_missing proxysql_connections_discrepancies; do
          [ -h $p/${check}.yaml ] && mv $p/${check}.yaml $p/${check}.yaml_disabled
        done
        if systemctl -q is-active datadog-agent; then
          systemctl restart datadog-agent
        fi
      user: root

  procRedeploy:
    # Parameters:
    #   - upgradeJahia: true or false (false = rolling redeploy)
    #   - targetDockerTag: jahia version string (eg: 8.0.2.0)
    #   - useExistingVolumes: true or false
    - cmd [proc]:
        - echo 'export JAHIA_UPGRADE="${this.upgradeJahia}"' >> /etc/locale.conf
      user: root
    - api: environment.control.RedeployContainersByGroup
      nodeGroup: proc
      tag: ${this.targetDockerTag}
      useExistingVolumes: ${this.useExistingVolumes}
      skipReinstall: false
      envName: ${env.envName}
    # restore-module-state is not compatible with rolling redeploy
    - if (${this.upgradeJahia}):
        - cmd [proc]: |-
            rm -fr /data/digital-factory-data/bundles-deployed/*
            sudo -u tomcat touch "/data/digital-factory-data/[persisted-bundles].dorestore"
            echo "restore-module-state have been asked"
            ls -l /data/digital-factory-data/*.dorestore
            touch /data/digital-factory-data/modules/*
            service tomcat start
          user: root
        - setJahiaUserFeedbacksConfig
    - cmd [proc]:
        - sed '/JAHIA_UPGRADE/d' -i /etc/locale.conf
      user: root
    - startupJahiaHealthCheck: ${nodes.proc.first.id}

  browsingNodesBulkRedeploy:
    # Parameters:
    #   - targetDockerTag: jahia version string (eg: 8.0.2.0)
    - api: environment.control.RedeployContainersByGroup
      nodeGroup: cp
      tag: ${this.targetDockerTag}
      useExistingVolumes: false
      skipReinstall: false
      envName: ${env.envName}

  browsingNodesRollingRedeploy:
    # Parameters:
    #   - targetDockerTag: jahia version string (eg: 8.0.2.0)
    - forEach (nodes.cp):
        - api: environment.control.RedeployContainerById
          nodeId: ${@i.id}
          tag: ${this.targetDockerTag}
          useExistingVolumes: true
          skipReinstall: false
          envName: ${env.envName}

  setVersionPropertiesValue:
    # Parameters:
    #   - targetJahiaVersion: Jahia version string (eg: "8.0.3.0")
    # Add jahia version in /data/digital-factory-data/info/version.properties before redeploy
    # in case we upgrade from a version that does not handle it to a version that does,
    # namely if we upgrade from Jahia < 7.3.8.0 to Jahia >= 7.3.8.0
    - set:
        currentJahiaVersion: ${nodes.proc.first.customitem.nodeVersion}
    - isVersionStrictlyLower:
        a: "${this.currentJahiaVersion}"
        b: "7.3.8.0"
        res: isCurrentVersionStriclyLowerThan7380
    - isVersionHigherOrEqual:
        a: "${this.targetJahiaVersion}"
        b: "7.3.8.0"
        res: isTargetVersionHigherOrEqual7380

    - if ( ${globals.isCurrentVersionStriclyLowerThan7380} && ${globals.isTargetVersionHigherOrEqual7380} ):
        cmd[proc,cp]: |-
          INFO_DIR="/data/digital-factory-data/info"
          if [ ! -f $INFO_DIR/version.properties ]; then
            mkdir -p $INFO_DIR
            echo "version=${this.currentJahiaVersion}" > $INFO_DIR/version.properties
          fi
        user: tomcat

  cleanJRLocalRevisionsTable:
    - cmd [${nodes.sqldb.first.id}]: |-
        mysql jahia -Nse "SELECT revision_id FROM JR_J_LOCAL_REVISIONS WHERE journal_id LIKE 'processing.%'"
        mysql jahia -e "TRUNCATE JR_J_LOCAL_REVISIONS"
    - set:
        currentRevision: ${response.out}
    - setEnvNodesAndRevision:
        target: proc
        currentRevision: ${this.currentRevision}
    - forEach(nodes.cp):
        setEnvNodesAndRevision:
          target: ${@i.id}
          currentRevision: ${this.currentRevision}
    - cleanJRJJournalTable:
        batchSize: 100000


  cleanJRJJournalTable:
    # Parameters:
    #   - batchSize: the number of lines to delete per batch
    - cmd [${nodes.sqldb.first.id}]: |-
        batch_size=${this.batchSize}
        query="SELECT MIN(REVISION_ID) FROM JR_J_LOCAL_REVISIONS;"
        min_revision_number=$(mysql jahia -sN -e "$query")
        if [ $? -ne 0 ]; then
          echo "Can't get the minimum revision number, aborting"
          exit 1
        fi
        query="DELETE FROM JR_J_JOURNAL WHERE REVISION_ID < $min_revision_number ORDER BY REVISION_ID LIMIT $batch_size"
        echo "Deleting rows with revision_id < $min_revision_number in table JR_J_JOURNAL. Batch size: $batch_size"
        n=1
        while true; do
          result=$(mysql jahia -vv -e "$query")
          if [ $? -ne 0 ]; then
            echo "Error when trying to delete the rows, aborting"
            exit 1
          fi
          if echo $result | grep -q " 0 rows affected"; then
            exit 0
          fi
          echo "Batch #$n executed"
          ((n+=1))
          sleep 2
        done

  setEnvNodesAndRevision:
    # Parameters:
    #   - target: target node group or id
    #   - currentRevision: Current Revision number
    - cmd [${this.target}]: awk '$1=="cluster.node.serverId" {print $NF; exit}' /opt/tomcat/conf/digital-factory-config/jahia/jahia.node.properties
    - cmd [${nodes.sqldb.first.id}]: |-
        node_name=${response.out}
        current_revision=${this.currentRevision}
        mysql jahia -e "INSERT INTO JR_J_LOCAL_REVISIONS values ('$node_name',$current_revision)"

  setupPat:
    # Parameters:
    # jahia_version: the jahia version
    - generatePatAndKey
    - savePatInVault:
        __secret__pat_token: ${globals.__secret__pat_token}
        __secret__pat_key: ${globals.__secret__pat_key}
    - setPatInJahia:
        __secret__pat_token: ${globals.__secret__pat_token}
        jahia_version: ${this.jahiaVersion}
    - setPatInHaproxy:
        __secret__pat_token: ${globals.__secret__pat_token}

  generatePatAndKey:
    - cmd[proc]: |-
        graph_token=$(cat /dev/urandom | tr -dc '[[:graph:]]' | fold -w 32 | head -n 1)
        token=$(echo -n "$graph_token" | base64)
        key=$(echo -n "$graph_token" | awk '{printf substr($1,0,16)}' | od -A n -t x1 | awk '{printf "%s%s%s%s-%s%s-%s%s-%s%s-%s%s%s%s%s%s",$1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16}')
        printf '{"HideThisOutput": true, "token": "%s", "key": "%s"}' "$token" "$key"

    - script: |-
        __secret__response = ${response.out};
        token = __secret__response["token"];
        key = __secret__response["key"];

        return {
          "result": 0,
          "onAfterReturn": {
            setGlobals: {
              "__secret__pat_token": token,
              "__secret__pat_key": key,
            }
          }
        };

  savePatInVault:
    # Parameters:
    #  - __secret__pat_token: PAT token
    #  - __secret__pat_key: PAT key
    - getVaultData
    - vaultSecretSet:
        secretPath: "paas/customers/${globals.organizationName}/paas_${env.shortdomain}/PAT/root"
        __secret__secretData: '{"token":"${this.__secret__pat_token}","key":"${this.__secret__pat_key}"}'

  setPatInJahia:
    # Parameters:
    # __secret__pat_token: the personal access token
    # jahia_version: the jahia version
    - cmd[proc]: |-
        __secret__pat_token=${this.__secret__pat_token}
        groovy_file_path=/data/digital-factory-data/patches/groovy/pat.groovy

        # Clean up any possible remainder of previous script execution
        rm -f ${groovy_file_path}*

        jahia_major_version=$(echo "${this.jahia_version}" | cut -d'.' -f1)
        if [ $jahia_major_version -eq 7 ]; then
          jahia_7_parameter=", null"
        else
          jahia_7_parameter=""
        fi

        echo """
        org.jahia.services.content.JCRTemplate.getInstance().doExecuteWithSystemSession({ session ->
          org.jahia.osgi.BundleUtils.getOsgiService(\"org.jahia.modules.apitokens.TokenService\"$jahia_7_parameter)
              .tokenBuilder(\"/users/root\", \"Jahia Cloud Token\", session)
              .setToken(\"$__secret__pat_token\")
              .setActive(true)
              .create()
          session.save();
        })
        """ >> $groovy_file_path

  setPatInHaproxy:
    # Parameters:
    # __secret__pat_token: the personal access token
    - script: |-
        __secret__patToken = "${this.__secret__pat_token}";
        return jelastic.env.control.AddContainerEnvVars(
          '${env.envName}',
          session,
          nodeGroup='bl',
          vars={"jahia_cfg_healthcheck_token": __secret__patToken}
        );

  getPatTokenAndKey:
    # set token value in __secret__pat_token and key value in __secret__pat_key if not already set
    - if ("HideThisLine" && "${globals.__secret__pat_token.print()}" == "" || "${globals.__secret__pat_key.print()}" == ""):
        - getVaultData
        - vaultSecretReadAllKeysB64:
            secretPath: "paas/customers/${globals.organizationName}/paas_${env.shortdomain}/PAT/root"
        - script: |-
            __secret__pat_creds_base64 = "${globals.__secret__vaultSecretData}";
            pat_creds = JSON.parse(java.lang.String(java.util.Base64.getDecoder().decode(__secret__pat_creds_base64)))
            return {
              "result": 0,
              "onAfterReturn": {
                setGlobals: {
                  "__secret__pat_token": pat_creds["token"],
                  "__secret__pat_key": pat_creds["key"]
                }
              }
            };

  checkPatGroovyScriptExecution:
    - cmd[proc]: |-
        groovy_file_path=/data/digital-factory-data/patches/groovy/pat.groovy
        jahia_running_timeout=360 # 6 minutes
        sleep_interval=5

        while [ -f $groovy_file_path ]; do
          sleep $sleep_interval;
          ((jahia_running_timeout-=sleep_interval))
          if [ $jahia_running_timeout -eq 0 ]; then
            echo "[ERROR] $groovy_file_path is still not executed after 360 seconds"
            exit 1
          fi
        done

        rm -f $groovy_file_path.installed

        if [ -f $groovy_file_path.failed ]; then
            echo "[ERROR] pat.groovy execution failed"
            exit 1
        fi

  isAugSearchEnabled:
    # Returns:
    #   ${globals.isAugSearchEnabled}: true if augmented search is enabled, false otherwise
    - script: |-
        const augsearch = jelastic.env.control.GetNodeGroups("${env.envName}", session).object.filter(function (object) {
            return object.name == "cp";
        }).pop().augsearch;

        resp = {"result": 0}
        resp.onAfterReturn = {
          setGlobals: {
            isAugSearchEnabled: (augsearch != null)
          }
        }

        return resp

  getAugSearchConnectionName:
    # Returns:
    #   - globals.augSearchConnectionName : contains the augmented search connection name configured, empty if there is nothing configured
    - getPatTokenAndKey
    - cmd[proc]: |-
        __secret__API_TOKEN="${globals.__secret__pat_token}"
        get_current_as_connection() {
          curl -fLSs http://localhost:8080/modules/graphql \
            -H "Authorization: APIToken $__secret__API_TOKEN" \
            -H 'Origin: http://localhost:8080' \
            -H 'Content-Type: application/json' \
            -d '{"query":"query { admin { search { currentConnection } } }"}' \
            | jq -r '.data.admin.search.currentConnection'
        }
        current_connection=$(get_current_as_connection)
        if [ "$current_connection" != "null" ]; then
          echo $current_connection
        fi

    - setGlobals:
        augSearchConnectionName: ${response.out}

  removeDefaultESConnection:
    # Delete the jahia-cloud_augmented-search connexion from elasticsearch-connector module
    - cmd[proc]: |-
        __secret__API_TOKEN="${globals.__secret__pat_token}"

        es_connection_name="jahia-cloud_augmented-search"
        result=$(curl -fLSs -XDELETE \
          -H "Authorization: APIToken $__secret__API_TOKEN" \
          -H 'Origin: http://localhost:8080' \
          -H 'Content-Type: application/json' \
          http://localhost:8080/modules/dbconn/elasticsearch/remove/$es_connection_name | jq -r ".success" )
        if [ "$result" != "Successfully removed ElasticSearch connection" ]; then
          echo "Failed to remove the old connection but may be normal, so we can continue"
        fi


  setDefaultESConnection:
    # Set the jahia-cloud_augmented-search connexion from elasticsearch-connector module
    - getPapiInfoAll
    - cmd[proc]: |-
        __secret__API_TOKEN="${globals.__secret__pat_token}"

        __secret__PAPI_TOKEN="${globals.papiToken}"
        export PAPI_TOKEN="$__secret__PAPI_TOKEN"
        export PAPI_HOSTNAME="${globals.papiHostname}"
        export PAPI_ENV_ID="${globals.papiEnvId}"
        export PAPI_API_VERSION="${globals.papiApiVersion}"

        environment=$(papi.py -X GET "paas-environment/$PAPI_ENV_ID")
        ec_deployment_id=$(echo $environment | jq -r .ec_deployment_id)
        ec_deployment=$(papi.py -X GET "ec-deployment/$ec_deployment_id")

        es_endpoint=$(echo $ec_deployment | jq -r .es_endpoint | sed 's/https:\/\/\(.*\):.*/\1/g')

        es_connection_name="jahia-cloud_augmented-search"

        __secret__elasticsearch_password="${globals.__secret__elasticsearch_password}"

        result=$(curl -fLSs -XPOST \
          -H 'Authorization: APIToken $__secret__API_TOKEN' \
          -H 'Origin: http://localhost:8080' \
          -H 'Content-Type: application/json' \
          -d "{\"id\": \"$es_connection_name\", \"isConnected\": true, \"host\": \"$es_endpoint\", \"port\": 443, \"user\": \"${env.envName}\", \"password\": \"$__secret__elasticsearch_password\", \"options\": {\"useXPackSecurity\": true, \"useEncryption\": true} }" \
          http://localhost:8080/modules/dbconn/elasticsearch/add
        )
        success=$(echo $result | jq -r .success)
        verified=$(echo $result | jq -r .connectionVerified)
        if [ "$success" != "Connection successfully added" ]; then
          echo "Failed to add the connection"
          exit 1
        elif [ "$verified" != "true" ]; then
          echo "The new connection could not be verified"
          exit 1
        fi

  setAugSearchESConnection:
    - getAugSearchConnectionName
    - if ("${globals.augSearchConnectionName}" != "jahia-cloud_augmented-search"):
        cmd[proc]: |-
          __secret__API_TOKEN="${globals.__secret__pat_token}"

          es_connection_name="jahia-cloud_augmented-search"

          response=$(curl -fLSs -XPOST \
            -H "Authorization: APIToken $__secret__API_TOKEN" \
            -H 'Origin: http://localhost:8080' \
            -H 'Content-Type: application/json' \
            -d '{"query":"mutation { admin { search { setDbConnection(connectionId:\"jahia-cloud_augmented-search\") } } }"}' \
            http://localhost:8080/modules/graphql)
            result=$(echo $response | jq -r '.data.admin.search.setDbConnection')
          if [ "$result" != "Successful" ]; then
            echo "Failed to use the $es_connection_name connection for AS: $response"
            exit 1
          fi

  #######################
  # jexperience related #
  #######################
  getEnvLinkedJcustomer:
    # Parameters:
    #   - envName: jahia env name to fetch info from
    - script: |
        const envName = "${this.envName}";

        unomi_linked = jelastic.env.control.GetNodeGroups(envName, session).object.filter(function (object) {
                                        return object.name == "cp";}).pop().envLink;

        return unomi_linked?
        {"result": 0, value: unomi_linked, "is_linked": true, "out": "Found a linked env"} :
        {"result": 0, value: "none", "is_linked": false, "out": "No unomi env linked"};
    - setGlobals:
        unomi_env_name: ${response.value}
        unomi_env_linked: ${response.is_linked}

  checkJexperienceCfg:
    # Parameters:
    #   - jcustomerDns: jahia env name to fetch info from
    #   - __secret__jcustomerPwdB64: Jcustomer password (base64 encoded)
    - cmd[proc]: |-
        CONFIG_FILE="/data/digital-factory-data/karaf/etc/org.jahia.modules.jexperience.settings-global.cfg"
        URL=$(grep jexperience.jCustomerURL $CONFIG_FILE | cut -d'=' -f2 | sed 's/ //g' |sed 's/https\?...//g')
        if [ "$URL" != "${this.jcustomerDns}" ]; then
          >&2 echo "error"
        fi
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "jCustomer url is wrong."
    - cmd[proc]: |-
        CONFIG_FILE="/data/digital-factory-data/karaf/etc/org.jahia.modules.jexperience.settings-global.cfg"
        PASSWD=$(sed -n 's/\( *jexperience.jCustomerPassword *= *\)\(.*\) *$/\2/p' $CONFIG_FILE | tr -d '\n' | base64)
        __secret__jcustomerPwdB64="${this.__secret__jcustomerPwdB64}"
        if [ "$PASSWD" != "$(echo -n $__secret__jcustomerPwdB64)" ]; then
          >&2 echo "error"
        fi
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "jCustomer password is wrong."

  removeAndCleanJexperience:
    - cmd[proc, cp]: |-
        JCUSTOMER_CONFIG_FILE="/data/digital-factory-data/karaf/etc/org.jahia.modules.jexperience.settings-global.cfg"
        if [ -f $JCUSTOMER_CONFIG_FILE ]; then
         sed -i 's/\(jexperience.jCustomer.*=\).*/\1/g' $JCUSTOMER_CONFIG_FILE
        fi
    - uninstallModule:
        moduleSymname: jexperience
    - environment.nodegroup.ApplyData [proc, cp]:
        data:
          envLink: null

  getKibanaEndpointOfJcustomer:
    # Parameters:
    # - jcustomerEnv
    # Returns:
    # - globals.kibanaEndpoint
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/jcustomer/get-kibana-endpoint.yml",
              envName: "${this.jcustomerEnv}"
            }
          );
    - setGlobals:
        kibanaEndpoint: "${response.successText.fromBase64()}"

  configureKibanaDashboard:
    # Parameters
    # roleAndAccountName: kibana role and es account name
    # __secret__password: es account password
    # jcustomer_env: jcustomer
    - set:
        es_permissions: '{"indices": [{"names": ["${this.jcustomer_env}_*"], "privileges": ["read"]}]}'
        kibana_permissions: '[{"base": ["all"], "feature": {}, "spaces": ["${this.roleAndAccountName}"]}]'
    - installOrUpgradeModule:
        moduleSymname: kibana-dashboards-provider
        moduleVersion: 0.2.1
        moduleGroupId: org.jahia.modules
        moduleRepository: marketing-factory-releases
    - installOrUpgradeModule:
        moduleSymname: jexperience-dashboards
        moduleVersion: 0.1.0
        moduleGroupId: org.jahia.modules
        moduleRepository: marketing-factory-releases
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/create-kibana-space.yml",
              envName: "${this.jcustomer_env}",
              settings: {
                'spaceName': '${this.roleAndAccountName}',
              }
            }
          );
    - script: |-
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/create-kibana-role.yml",
              envName: "${this.jcustomer_env}",
              settings: {
                'roleName': '${this.roleAndAccountName}',
                'esPermissions': '${this.es_permissions}',
                'kibanaPermissions': '${this.kibana_permissions}'
              }
            }
          );
    - script: |-
        var __secret__password = "${this.__secret__password}";
        return api.marketplace.jps.Install(
            {
              jps: "${globals.repoRootUrl}/packages/common/create-elasticsearch-account.yml",
              envName: "${this.jcustomer_env}",
              settings: {
                'accountName': '${this.roleAndAccountName}',
                'password': __secret__password,
                'rolesList': '${this.roleAndAccountName},editor',
              }
            }
          );
    - getKibanaEndpointOfJcustomer:
        jcustomerEnv: ${this.jcustomer_env}
    - cmd[proc]: |-
        __secret__password="${this.__secret__password}"
        cfg_file=/data/digital-factory-data/karaf/etc/org.jahia.modules.kibana_dashboards_provider.cfg
        sed -i "s,.*\(kibana_dashboards_provider.kibanaURL\).*,\1=${globals.kibanaEndpoint},g" $cfg_file
        sed -i 's/.*\(kibana_dashboards_provider.kibanaUser\).*/\1=${this.roleAndAccountName}/g' $cfg_file
        sed -i "s/.*\(kibana_dashboards_provider.kibanaPassword\).*/\1=$__secret__password/g" $cfg_file
        sed -i 's/.*\(kibana_dashboards_provider.kibanaSpace\).*/\1=${this.roleAndAccountName}/g' $cfg_file
        sed -i 's/.*\(kibana_dashboards_provider.kibanaProxy.enable\).*/\1=true/g' $cfg_file
        sed -i 's/.*\(kibana_dashboards_provider.kibanaProxy.cloud\).*/\1=true/g' $cfg_file

  createKibanaAdminAccount:
    # Parameters:
    # - accountName: name of the kibana admin user
    # - rolesList: comma-separated list of Kibana roles
    # - __secret__password: kibana admin user's password
    # - jcustomerEnv: target jcustomer environment
  - setGlobalRepoRootUrl
  - script: |-
      var __secret__password = "${this.__secret__password}";
      return api.marketplace.jps.Install(
          {
            jps: "${globals.repoRootUrl}/packages/common/create-elasticsearch-account.yml",
            envName: "${this.jcustomerEnv}",
            settings: {
              'accountName': '${this.accountName}',
              'password': __secret__password,
              'rolesList': '${this.rolesList}',
            }
          }
        );

### Vault related actions ###
  vaultGetIPsecConfB64:
    # Returns:
    #   ${globals.__secret__IPsecConfB64}: the IPsec conf, base64 encoded
    - getVaultData
    - vaultSecretReadKeyB64:
        secretPath: paas/customers/${globals.organizationName}/paas_${env.shortdomain}/ipsec/conn-1
        secretKey: conf
    - setGlobals:
        __secret__IPsecConfB64: ${globals.__secret__vaultSecretData}

  vaultGetIPsecPSKB64:
    # Returns:
    #   ${globals.__secret__IPsecPSKB64}: the PSK, base64 encoded
    - getVaultData
    - vaultSecretReadKeyB64:
        secretPath: paas/customers/${globals.organizationName}/paas_${env.shortdomain}/ipsec/conn-1
        secretKey: secret
    - setGlobals:
        __secret__IPsecPSKB64: ${globals.__secret__vaultSecretData}
