---
# Depends on:
#   - common.yml

globals:
  proxysql_cli: "mysql -h 127.0.0.1 -uadmin -padmin -P6032"
  org_jahia_ehcachemanager_maxBytesLocalHeap_dev: 700M
  org_jahia_ehcachemanager_big_maxBytesLocalHeap_dev: 700M
  org_jahia_ehcachemanager_maxBytesLocalHeap_prod: 800M
  org_jahia_ehcachemanager_big_maxBytesLocalHeap_prod_cp: 2500M
  org_jahia_ehcachemanager_big_maxBytesLocalHeap_prod_proc: 700M
  expandImportedFilesOnDisk: "true"
  jahiaFileUploadMaxSize: 268435456
  imageService: ImageMagickImageService
  jahiaImageMagickPath: /usr/bin
  java_opts:
    -DDB_USER=${DB_USER}
    -DDB_PASSWORD=${DB_PASSWORD}
    -DREDIS_PASSWORD=${REDIS_PASSWORD}
    -DMANAGER_USER=${MANAGER_USER}
    -DHOST_NAME=$(hostname)
    -Dcom.sun.management.jmxremote
    -Dcom.sun.management.jmxremote.port=7199
    -Dcom.sun.management.jmxremote.ssl=false
    -Dcom.sun.management.jmxremote.authenticate=false
    -XX:MaxPermSize=512m
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:+PrintConcurrentLocks
    -XX:+UseParallelGC
    -XX:SurvivorRatio=8
    -Xmn1G

actions:
  #################
  # jahia related #
  #################
  onAfterBrowsingScaleOut:
    - setSudoer: ${this.newNode}
    - copyApp: ${this.newNode}
    - setToolsPwd: ${this.newNode}
    - setupDatadogAgentJahia: ${this.newNode}
    - cmd[${this.newNode}]: |-
        if (service tomcat status); then
          echo "Now Restarting Tomcat"
          service tomcat restart
        else
          echo "Now Launching Tomcat"
          service tomcat start
        fi
      user: root

  onAfterRedeployJahiaContainer:
    - cmd[${this}]:
        - service tomcat stop
      user: root
    - getMavenPath
    - env.control.AddContainerEnvVars [cp, proc]:
      vars:
        jahia_cfg_mvnPath: ${globals.jahia_cfg_mvnPath}
    - setSudoer: ${this}
    - getLogEventScript: ${this}
    - if (nodes.sqldb.length == 1):
        - disableDatadogCustomChecks
    - copyApp: ${this}
    - setToolsPwd: ${this}
    - if ("${this}" == "cp"):
        cmd[${this}]:
          - sed -i "s#\(processingServer\s*=\).*#\1 false#g" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
    - setupDatadogAgentJahia: ${this}
    - cmd[${this}]: |-
          touch "/data/digital-factory-data/[persisted-configurations].dorestore"
          chown tomcat: "/data/digital-factory-data/[persisted-configurations].dorestore"
          source /etc/locale.conf
          echo "JAHIA_UPGRADE=$JAHIA_UPGRADE"
          if [ "$JAHIA_UPGRADE" == "true" ]; then
            echo "This is an upgrade, processing's tomcat will not be restarted now"
          else
            echo "This is a regular redeploy, restart tomcat now"
            service tomcat start
          fi
      user: root

    - script: |-
        ipsec_enabled = jelastic.env.control.GetNodeGroups("${env.envName}", session).object.filter(function (object) {
                          return object.name == "cp";
                        }).pop().ipsec
        return {"result": 0, "out": ipsec_enabled}

    - setGlobals:
        strongswanServiceStatus: ${response.out}

    - if ("${globals.strongswanServiceStatus}" == "enable"):
        - cmd[${this}]: |-
            systemctl enable strongswan.service
            systemctl start strongswan.service
          user: root

  stopJahia:
    cmd[${this}]: "service tomcat stop"
    user: root

  initJahiaDatabase:
    - log: "## Import DX schema in database"
    - cmd[${nodes.proc.first.id}]: cat $DATA_PATH/digital-factory-data/db/sql/schema/mysql/*.sql | mysql -h $DB_ENDPOINT -u$DB_USER -p$DB_PASSWORD -f jahia

  getMavenPath:
    - cmd [${nodes.proc.first.id}]: echo $(ls -d /opt/*maven*/bin/mvn)
    - setGlobals:
        jahia_cfg_mvnPath: ${response.out}

  installJahia:
    # Parameters:
    #   - jahiaVersion
    #   - rootpwd: Jahia root user password
    #   - toolspwd: Jahia Tools password
    - setSudoer: proc, cp
    - getLogEventScript: proc, cp

    - environment.nodegroup.ApplyData [proc, cp]:
        data:
          productName: dx
          productVersion: ${this.jahiaVersion}
    - initJahiaDatabase
    - log: "## Determine JDK version for good _JAVA_OPTIONS envvar"
    - cmd[proc, cp]: |-
        case "$($JAVA_HOME/bin/java -version 2>&1 | awk 'NR==1 {print gensub("(\"|_.*)", "", "g", $3)}')" in
          1.8*)
              j_opts='${globals.java_opts}'
              ;;
          *)
              j_opts='${globals.java_opts} -Xlog:gc:file=/opt/tomcat/logs/gc.log:time,uptime,level,pid,tid,tags'
              ;;
        esac
        sed -e '2isource /etc/profile' -e "s#\(^JAVA_OPTS=.*\)\(\"$\)#\1 ${j_opts}\2#" -i /opt/tomcat/conf/tomcat-env.sh
    - setJahiaPropertiesEnvvars
    - copyApp: proc, cp
    - cmd[proc]: |-
        base64 -d <<< "${this.rootpwd.toBase64()}" > $DATA_PATH/digital-factory-data/root.pwd
      user: tomcat
    - defineToolsPwd:
        toolspwd: ${this.toolspwd}
    - setToolsPwd: proc, cp
    - api: env.control.ExecDockerRunCmd
      nodeId: ${nodes.proc.first.id}
    - checkPatGroovyScriptExecution
    - startupJahiaHealthCheck: proc
    - env.control.ExecDockerRunCmd [${nodes.cp.join(id,)}]

  setJahiaPropertiesEnvvars:
    - log: "## Setting jahia.properties envvars"
    - getMavenPath
    - env.control.AddContainerEnvVars [cp, proc]:
      vars:
        jahia_cfg_expandImportedFilesOnDisk: ${globals.expandImportedFilesOnDisk}
        jahia_cfg_jahiaFileUploadMaxSize: ${globals.jahiaFileUploadMaxSize}
        jahia_cfg_imageService: ${globals.imageService}
        jahia_cfg_imageMagickPath: ${globals.jahiaImageMagickPath}
        jahia_cfg_mvnPath: ${globals.jahia_cfg_mvnPath}

  copyApp:
    - log: "## Copying Jahia app and setting its properties"
    - cmd[${this}]: |-
        [ "$_ROLE" == "Browsing" ] && sed -i "s#\(processingServer\s*=\).*#\1 false#g" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
        rm -rf $STACK_PATH/webapps/*
        #COPS-18 workaround, switch from loadbalance to sequential
        replace="sequential:"
        sed "s/loadbalance:/$replace/" -i /$DATA_PATH/jahia/tomcat/webapps/ROOT/META-INF/context.xml
        cp -rf $DATA_PATH/jahia/tomcat/webapps/* $STACK_PATH/webapps
        chown -R tomcat:tomcat $STACK_PATH/webapps
        tomcat_env=/opt/tomcat/conf/tomcat-env.sh
        short_name=$(echo ${_ROLE}.$HOSTNAME | sed -r 's/^([a-Z]+)\.[a-Z]+([0-9]+)-.+$/\1.\2/' | tr 'A-Z' 'a-z')
        sed -i "s|^cluster.node.serverId.*|cluster.node.serverId = $short_name|" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
        # the follwing will update or add if not present the jvmRoute property
        sed -i -n -e '/^\s*jahia.session.jvmRoute\s*=/!p' -e "\$ajahia.session.jvmRoute = $short_name" $STACK_PATH/conf/digital-factory-config/jahia/jahia.node.properties
        grep -q '^JMX_OPTS=\-XX:+UseParallelGC$' ${tomcat_env} || sed -i "2i JMX_OPTS=\-XX:+UseParallelGC" ${tomcat_env}
        sed -i '/<!-- Access log processes all example./i \\t<!-- Remote IP Valve -->\n \t<Valve className="org.apache.catalina.valves.RemoteIpValve" protocolHeader="X-Forwarded-Proto" />\n' /opt/tomcat/conf/server.xml
        #Secure cookies from cross scripting
        indent="      " && printf "$indent<cookie-config>\n$indent$indent<secure>true</secure>\n$indent$indent<http-only>true</http-only>\n$indent</cookie-config>\n" > /tmp/cookies-config
        sed -i '/<session-config>/r /tmp/cookies-config' /opt/tomcat/conf/web.xml && rm /tmp/cookies-config
        # the following will update or add if not present these attributes: jvmRoute, maxPostSize, maxHttpHeaderSize
        xmlstarlet ed -P -L -S \
          -u "Server/Service/Engine/@jvmRoute" -v "$short_name" \
          -i "Server/Service/Engine[not(@jvmRoute)]" -t attr -n "jvmRoute" -v "$short_name" \
          -u "Server/Service/Connector[@port='80']/@maxPostSize" -v '${maxPostSize}' \
          -i "Server/Service/Connector[@port='80' and not(@maxPostSize)]" -t attr -n "maxPostSize" -v '${maxPostSize}' \
          -u "Server/Service/Connector[@port='80']/@maxHttpHeaderSize" -v '65536' \
          -i "Server/Service/Connector[@port='80' and not(@maxHttpHeaderSize)]" -t attr -n "maxHttpHeaderSize" -v '65536' \
          /opt/tomcat/conf/server.xml
        grep -q '^jahia_cfg_cluster_tcp_bindAddress=' ${tomcat_env} || sed -i '/TOMCAT_USER=/ a jahia_cfg_cluster_tcp_bindAddress=$(hostname -i)' ${tomcat_env}
        grep -q '^JAVA_OPTS.*-DmaxPostSize=' ${tomcat_env} || sed -i -E '/^JAVA_OPTS/ s/(.)$/ -DmaxPostSize=${tomcat_cfg_maxpostsize}\1/g' ${tomcat_env}
        grep -q '^JAVA_OPTS.*-XX:NativeMemoryTracking=' ${tomcat_env} || sed -i -E '/^JAVA_OPTS/ s/(.)$/ -XX:NativeMemoryTracking=summary\1/g' ${tomcat_env}
        # Datadog APM
        grep -q '^APM_OPTS=*' ${tomcat_env} || echo 'APM_OPTS="-Ddd.profiling.enabled=true -XX:FlightRecorderOptions=stackdepth=256 -Ddd.logs.injection=true -javaagent:/opt/tomcat/datadog/dd-java-agent.jar -Ddd.service=jahia -Ddd.env=${env.domain} -Ddd.trace.classes.exclude=org.jahia.modules.forms.dsl.*,org.jahia.modules.databaseConnector.dsl.*"' >>  ${tomcat_env}
        grep -q '^$DATADOG_APM_ENABLED*' ${tomcat_env} || echo '$DATADOG_APM_ENABLED && JAVA_OPTS+=" $APM_OPTS"' >> ${tomcat_env}

    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when installing jahia."

  defineToolsPwd:
    # Parameters:
    #   - toolspwd: Jahia Tools password
    - log: "## Now setting tools password"
    - setGlobalRepoRootUrl
    - cmd[proc]: |-
        if [ ! -f /usr/local/bin/reset-jahia-tools-manager-password.py ]; then
          curl -fLSso /usr/local/bin/reset-jahia-tools-manager-password.py ${globals.repoRootUrl}/assets/jahia/reset-jahia-tools-manager-password.py || exit 1
          chmod u+x /usr/local/bin/reset-jahia-tools-manager-password.py
        fi
        /usr/local/bin/reset-jahia-tools-manager-password.py "${this.toolspwd.toBase64()}" $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties
      user: root
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "An error occurred when defining tools password."
    - cmd [proc]: awk '$1=="jahiaToolManagerPassword" {print $NF}' $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties
    - set:
        jahiaToolManagerPassword: ${response.out}
    - cmd [cp]: |-
        sed -i 's,^\s*\(jahiaToolManagerPassword\s*=\).*$,\1 ${this.jahiaToolManagerPassword},' $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties
    - env.control.AddContainerEnvVars [proc, cp]:
      vars:
        MANAGER_PASSWORD: ${this.jahiaToolManagerPassword}

  setToolsPwd:
    - cmd[${this}]: |-
         sed -i "s|^jahiaToolManagerPassword .*$|jahiaToolManagerPassword = $MANAGER_PASSWORD|" $STACK_PATH/conf/digital-factory-config/jahia/jahia.properties

  setupDatadogAgentJahia:
    - log: "## Finalize Datadog agent setup on ${this}"
    - setGlobalRepoRootUrl
    - cmd[${this}]: |-
        NODE_NAME=${HOSTNAME/-*}
        echo "hostname: ${_ROLE}.${NODE_NAME#node}" >> /etc/datadog-agent/datadog.yaml

        # Disable APM by default
        echo "apm_config:" >> /etc/datadog-agent/datadog.yaml
        echo "  enabled: ${DATADOG_APM_ENABLED:-false}" >> /etc/datadog-agent/datadog.yaml

        sed 's/service: jahia/service: ${env.shortdomain}/' -i /etc/datadog-agent/conf.d/tomcat.d/conf.yaml
        sed 's/service: jahia/service: ${env.shortdomain}/' -i /etc/datadog-agent/conf.d/proxysql.d/conf.yaml
        sed 's/service: jahia/service: ${env.shortdomain}/' -i /etc/datadog-agent/conf.d/strongswan_connections_status.yaml
        chmod 644 /opt/tomcat/logs/catalina.out
        mkdir /etc/datadog-agent/conf.d/jelastic.d /var/log/jelastic-packages
        chown tomcat:root /var/log/jelastic-packages
        chown dd-agent: /etc/datadog-agent/conf.d/jelastic.d
        curl -fLSso /etc/datadog-agent/conf.d/jelastic.d/conf.yaml ${globals.repoRootUrl}/assets/common/dd_agent_jelastic_package_conf.yml || exit 1
        /usr/local/bin/set_dd_tags.sh
        systemctl restart crond
        systemctl enable datadog-agent
      user: root

  startupJahiaHealthCheck:
    # Two arguments:
    #   - target: Mandatory, the target nodeId or nodeGroup. If the duration is not specified, the target
    #     can be passed as a parameter directly after the action name, e.g.: startupJahiaHealthCheck: <target>
    #   - duration: Optional, duration in seconds. Default value of 24 hours if not specified
    # The .print() call surrounded by simple quotes is the only working way I found to test if the variable exists
    - if ('${this.print()}' != ''):
        set:
          target: ${this}
    - else:
        set:
    - getPatTokenAndKey
    - cmd [${this.target}]: |-
        __secret__jahia_cfg_healthcheck_token=${globals.__secret__pat_token}
        if ! tomcat_pid=$(pgrep -u tomcat -f java); then
          echo "[ERROR] Tomcat process not found, please check." >&2
          exit 1
        fi

        if [ ! -f /var/log/tomcat/jahia.log ]; then
          echo "[ERROR] Jahia log file not found, it seems there is a problem with tomcat instance, please check." >&2
          exit 2
        fi

        startup_line=$(grep -n "s t a r t i n g" /opt/tomcat/logs/catalina.out | tail -n1 | cut -d":" -f1)
        timeout=$(date --date="+$HEALTHCHECK_DURATION minutes" +%s)
        hc_url="http://127.0.0.1:8080/modules/healthcheck?severity=critical"

        # Number of minutes allowed for healthcheck to be completed once tomcat startup is finished
        jahia_running_timeout=5

        while [ $(date +%s) -lt $timeout ]; do
          # First we test if Jahia is up with a curl request.
          if curl_resp=$(curl -f -s -m 1 "$hc_url" -H "authorization: APIToken $__secret__jahia_cfg_healthcheck_token"); then
            status=$(echo $curl_resp | jq -r ".status.health")
            if [ "$status" = "GREEN" ] || [ "$status" = "YELLOW" ]; then
              exit 0
            fi
          fi

          # If it isn't, we first check tomcat process status
          if ! ps --pid $tomcat_pid > /dev/null; then
            echo "[ERROR] Tomcat process no more running, please check." >&2
            exit 3
          fi
          # Then we check Jahia startup status, all
          tail -n +${startup_line} /opt/tomcat/logs/catalina.out | grep -q "Server startup in"
          if [ $? -eq 0 ]; then
            if [ $jahia_running_timeout -eq 0 ]; then
              echo "[ERROR] Tomcat startup is finished but healthcheck failed, please check." >&2
              exit 4
            fi
            ((jahia_running_timeout-=1))
          fi

          sleep 60
        done

        echo "[ERROR] Timeout, the Tomcat process is still running but Jahia is not started yet" >&2
        exit 5

  checkJahiaHealth:
    - getPatTokenAndKey
    - cmd [${this}]: |-
        __secret__jahia_cfg_healthcheck_token=${globals.__secret__pat_token}
        if ! tomcat_pid=$(pgrep -u tomcat -f java); then
          echo "[ERROR] Tomcat process not found, please check" >&2
          exit 1
        fi

        hc_url="http://127.0.0.1:8080/modules/healthcheck?severity=critical"

        if curl_resp=$(curl -f -s -m 1 "$hc_url" -H "authorization: APIToken $__secret__jahia_cfg_healthcheck_token"); then
          status=$(echo $curl_resp | jq -r ".status.health")
          if [ "$status" = "GREEN" ] || [ "$status" = "YELLOW" ]; then
            exit 0
          fi
        fi
        echo "[ERROR] Healthcheck result different from GREEN or YELLOW, exiting" 1>&2 && exit 1

  checkJahiaDatadogCustomChecks:
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: proxysql
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: jahia_node_not_in_haproxy_pool
    - checkDatadogAgentCheck:
        target: ${this}
        checkName: strongswan_connections_status

  deleteEnvLinkJahia:
    # Parameters:
    #   - jCustomerEnv: Jcustomer env name in the env link of Jahia
    # Returns:
    #   - ${response.link_removed}: true or false (true if Jahia env is removed from envLink of Jcustomer)
    - script: |-
        const envName = "${env.envName}";
        const jCustomerEnv = "${this.jCustomerEnv}";
        envsLinked = jelastic.env.control.GetNodeGroups(jCustomerEnv, session).object.filter(function (object) {
                                return object.name == "cp";
                              }).pop().envLink;
        if (envsLinked.indexOf(envName) == -1) {
          return {"result": 0, "link_removed": false, "out": envName + " not in envLink of " + jCustomerEnv};
        }

        // envLink can contain multiple Jahia envs on jCustomer side separated by a comma
        if (envsLinked.indexOf(",") != -1) {
          envsLinkedArr = envsLinked.split(",");
          envsLinkedArr.splice(envsLinkedArr.indexOf(envName), 1);
          newEnvLink = String(envsLinkedArr);
        } else {
          newEnvLink = null;
        }
        resp = jelastic.env.nodegroup.ApplyData(jCustomerEnv, session, nodeGroup='cp', data={'envLink': newEnvLink});
        return {"result": 0, "link_removed": true, "out": envName + " removed from envLink of " + jCustomerEnv};

  isFullReadonlyEnabled:
    - cmd[proc]: |-
        RO_ON=$(ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR full-read-only | grep -e Current -e local | grep ON)
        if [ "$RO_ON" == "" ]; then
          echo false
        else
          echo true
        fi
    - setGlobals:
        RO: "${response.out}"

  switchFullReadonly:
    - log: "switch full read mode to ${this.fullreadmode} on nodegroup ${this.group}"
    - cmd[${this.group}]: |-
          ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR full-read-only ${this.fullreadmode}

  enableKarafLogin:
    - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
      script: |-
          try {
            var resp = JSON.parse(isKarafLoginEnabled)["${this}"]
          } catch(error) {
            var resp = false
          }
          return {"result": 0, "resp": resp}
    - if(${response.resp}):
        - log: "karaf login is already enabled, nothing to do"
    - else:
        - log: "Activate karaf's ssh login on ${this}"
        - cmd[${this}]: |-
            # Clear everything and enable karaf login
            [ -f /tmp/abricot ] && rm /tmp/abricot
            [ -f /tmp/abricot.pub  ] && rm /tmp/abricot.pub
            ssh-keygen -t rsa -f /tmp/abricot -P ""
            awk '{printf "abricot:%s,_g_:admingroup\n",$2}' /tmp/abricot.pub >> /data/digital-factory-data/karaf/etc/keys.properties
            sed 's,\(sshRealm\s*=\s*\)jahia,\1karaf,' -i /data/digital-factory-data/karaf/etc/org.apache.karaf.shell.cfg
            i=1
            it=66
            until (ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR full-read-only); do
              echo "karaf ssh login not updated yet (iteration $i/$it)"
              if [ $i -ge $it ]; then
                echo "Too long to start, something is wrong here... EXITING"
                exit 1
              fi
              ((i++))
              sleep 1
            done
        - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
          script: |-
            try {
              var isEnable = JSON.parse(isKarafLoginEnabled)
            } catch(error) {
              var isEnable = {}
            } finally {
              isEnable["${this}"] = true
            }
            return {"result": 0, "isEnable": isEnable}
        - setGlobals:
            isKarafLoginEnabled: ${response.isEnable}
            karafConsole: "ssh abricot@localhost -p 8101 -i /tmp/abricot -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR"

  disableKarafLogin:
    - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
      script: |-
          try {
            var resp = JSON.parse(isKarafLoginEnabled)["${this}"]
          } catch(error) {
            var resp = false
          }
          return {"result": 0, "resp": resp}
    - if(! ${response.resp}):
        - log: "karaf login is already disabled, nothing to do"
    - else:
        - log: "Disable karaf's ssh login on ${this}"
        - cmd[${this}]: |-
            [ -f /tmp/abricot  ] && rm /tmp/abricot
            [ -f /tmp/abricot.pub  ] && rm /tmp/abricot.pub
            sed '/^abricot:/d' -i /data/digital-factory-data/karaf/etc/keys.properties
            sed 's,\(sshRealm\s*=\s*\)karaf,\1jahia,' -i /data/digital-factory-data/karaf/etc/org.apache.karaf.shell.cfg
        - isKarafLoginEnabled: ${globals.isKarafLoginEnabled}
          script: |-
            try {
              var isEnable = JSON.parse(isKarafLoginEnabled)
            } catch(error) {
              var isEnable = {}
            } finally {
              isEnable["${this}"] = false
            }
            return {"result": 0, "isEnable": isEnable}
        - setGlobals:
            isKarafLoginEnabled: ${response.isEnable}

  enableFullReadOnlyOnCluster:
    - getJahiaVersion

    - enableKarafLogin: proc
    - isFullReadonlyEnabled

    - if(!${globals.RO}):
        - switchFullReadonly:
            group: "proc"
            fullreadmode: "ON"

        - isVersionStrictlyLower:
            a: ${globals.jahiaVersion}
            b: 7.3.3.0
            res: enableVersionLowerThan7330

        - if( ${globals.enableVersionLowerThan7330} ):
            - enableKarafLogin: cp
            - switchFullReadonly:
                group: "cp"
                fullreadmode: "ON"

  disableFullReadOnlyOnCluster:
    - getJahiaVersion
    - isFullReadonlyEnabled

    - if(${globals.RO}):
        - switchFullReadonly:
            group: "proc"
            fullreadmode: "OFF"
        - disableKarafLogin: proc

        - isVersionStrictlyLower:
            a: ${globals.jahiaVersion}
            b: 7.3.3.0
            res: disableVersionLowerThan7330

        - if( ${globals.disableVersionLowerThan7330} ):
            - switchFullReadonly:
                group: "cp"
                fullreadmode: "OFF"
            - disableKarafLogin: cp

  getJahiaVersion:
    - log: "Get jahia version"
    - script: |-
        var resp = jelastic.env.control.GetEnvInfo('${env.envName}', session)
        for (var i = 0, g = resp.nodes; i < g.length; i++) {
          if (g[i].nodeGroup == "proc") {
            var jahia_version = g[i].version.split("-", 1)[0]
            break
            }
          }
        return {'result': 0, 'jahia_version': jahia_version}
    - setGlobals:
        jahiaVersion: ${response.jahia_version}
    - log: "Jahia is v${globals.jahiaVersion}"

  upgradeModule:
    # Installs the specified version of a module and deletes all the previous versions if installed.
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - module_version: the version of the module to install
    - checkIfModuleIsInstalled:
        module_symname: ${this.module_symname}
        module_version: ${this.module_version}
    - if (!${globals.moduleInstalled}):
        - installModule:
            module_symname: ${this.module_symname}
            module_version: ${this.module_version}
            start_module: true
    - else:
        - isVersionHigherOrEqual:
            a: "${this.module_version}"
            b: "${globals.mostRecentInstalledVersion}"
            res: needsInstall
        - if (${globals.needsInstall}):
            - installModule:
                module_symname: ${this.module_symname}
                module_version: ${this.module_version}
                start_module: true
    - checkIfModuleVersionIsInstalled:
        module_symname: ${this.module_symname}
        module_version: ${this.module_version}
    - checkIfModuleVersionIsStarted:
        module_symname: ${this.module_symname}
        module_version: ${this.module_version}
    - if (!${globals.moduleStarted}):
        - startModule:
            module_symname: ${this.module_symname}
            module_version: ${this.module_version}
    - uninstallOldVersionsOfModule:
        module_symname: ${this.module_symname}
        module_version: ${this.module_version}

  checkIfModuleIsInstalled:
    # Checks if a module is installed (at least one version) and returns true if it is (false otherwise).
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    # Returns:
    #   - globals.moduleInstalled: true if the module is installed, false otherwise
    #   - globals.mostRecentInstalledVersion: if globals.moduleInstalled is true, then globals.mostRecentInstalledVersion
    #       is the most recent version installed
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - cmd [proc]: |-
        resp=$(${this.curl} "localhost/modules/api/bundles/${this.module_symname}/*/_localInfo")
        case "$(jq -r ". | length" <<< $resp)" in
          "0") # Means the module is not installed
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *)
            jq -r "keys[]" <<< $resp | awk -F'/' '{print $NF}' | sort -nr | head -1
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module verification."
    - elif ("${response.out}" == ""):
        - log: Module ${this.module_symname} v${this.module_version} is not installed
        - setGlobals:
            moduleInstalled: false
    - else:
        - log: Module ${this.module_symname} v${this.module_version} is installed
        - setGlobals:
            moduleInstalled: true
            mostRecentInstalledVersion: ${response.out}

  checkIfModuleVersionIsInstalled:
    # Checks if the specific version of a module is installed and returns true if it is (false otherwise).
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - module_version: the version of the module to check
    # Returns:
    #   - globals.moduleInstalled: true if the module is installed, false otherwise
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - cmd [proc]: |-
        resp=$(${this.curl} "localhost/modules/api/bundles/${this.module_symname}/${this.module_version}/_localInfo")
        case "$(jq -r .moduleState <<< $resp)" in
          INSTALLED|STARTED|RESOLVED|STARTING|STOPPING|ACTIVE) # If the module is not installed, the value would be "UNINSTALLED" or "null" if 404 is returned
            echo "Module installed"
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module verification."
    - elif ("${response.out}" == ""):
        - log: Module ${this.module_symname} v${this.module_version} is not installed
        - setGlobals:
            moduleInstalled: false
    - else:
        - log: Module ${this.module_symname} v${this.module_version} is installed
        - setGlobals:
            moduleInstalled: true

  installModule:
    # Downloads a module jar file and installs it. The module can also be started at the same time.
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - module_version: the version of the module to install
    #   - start_module (optional): if the module should be started or not, true or false. Default: false
    #   - jar_url (optional): the URL to download the jar file. Default: https://store.jahia.com/cms/mavenproxy/private-app-store/org/jahia/modules
    - set:
        modulesUrl: https://store.jahia.com/cms/mavenproxy/private-app-store/org/jahia/modules
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - if ('${this.start_module.print()}' == ''):
        set:
          start_module: "false"
    - if ('${this.jar_url.print()}' == ''):
        set:
          jar_url: ""
    - getPatTokenAndKey
    - log: Installing new ${this.module_symname} v${this.module_version}
    - cmd [proc]: |-
        if [[ "${this.jar_url}" == "" ]]; then
          url="${this.modulesUrl}/${this.module_symname}/${this.module_version}/${this.module_symname}-${this.module_version}.jar"
        else
          url=${this.jar_url}
        fi
        tmp_dir=$(mktemp -d)
        local_jar_file=$tmp_dir/${this.module_symname}-${this.module_version}.jar
        curl -fLSso $local_jar_file $url >&2
        if [ $? -ne 0 ]; then
          echo "download failed"
          rm -rf $tmp_dir
          exit 0
        fi
        resp=$(${this.curl} -XPOST \
                 --form bundle=@$local_jar_file \
                 --form start=${this.start_module} \
                 localhost/modules/api/bundles)
        case "$(jq -r .bundleInfos <<< $resp)" in
          "null") # If install failed, there is no bundleInfos attribute in the JSON response
            echo "error"
            jq -r .message <<< $resp >&2
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module was installed, nothing to do
            ;;
        esac
        rm -rf $tmp_dir
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module installation."
    - log: Module ${this.module_symname} v${this.module_version} has been installed

  uninstallModuleVersion:
    # Uninstalls the specified version of a module.
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - module_version: the version of the module to install
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - log: Uninstalling ${this.module_symname} v${this.module_version}
    - cmd [proc]: |-
        resp=$(${this.curl} -XPOST -d "" \
              "localhost/modules/api/bundles/${this.module_symname}/${this.module_version}/_uninstall")
        case "$(jq -r .bundleInfos <<< $resp)" in
          "null") # If uninstall failed, there is no bundleInfos attribute in the JSON response
            echo "error"
            jq -r .message <<< $resp >&2
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module was uninstalled, nothing to do
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module uninstall."
    - log: Version ${this.module_version} of ${this.module_symname} module uninstalled

  checkIfModuleVersionIsStarted:
    # Checks if the specified version of a module is started and returns true if it is (false otherwise).
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - module_version: the version of the module to install
    # Returns:
    #   - globals.moduleStarted: true if the module is started, false otherwise
    - setGlobals:
        moduleStarted: true
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - cmd [proc]: |-
        module_info=$(${this.curl} "localhost/modules/api/bundles/${this.module_symname}/${this.module_version}/_localInfo")
        case "$(jq -r .moduleState <<< $module_info)" in
          STARTED)
            echo "Module started"
            ;;
          ""|null|UNINSTALLED) # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module is installed but not started
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module verification."
    - if ("${response.out}" == ""):
        - log: Module ${this.module_symname} v${this.module_version} is not started
        - setGlobals:
            moduleStarted: false
    - else:
        - log: Module ${this.module_symname} v${this.module_version} is started
        - setGlobals:
            moduleStarted: true

  startModule:
    # Starts the specified version of a module.
    #
    # Parameters:
    #   - module_symname: the symbolic name of the module to upgrade (for instance "distributed-sessions")
    #   - module_version: the version of the module to install
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - log: Starting ${this.module_symname} v${this.module_version}
    - cmd [proc]: |-
        resp=$(${this.curl} -XPOST -d "" \
                 "localhost/modules/api/bundles/${this.module_symname}/${this.module_version}/_start")
        case "$(jq -r .bundleInfos <<< $resp)" in
          "null") # If install failed, there is no bundleInfos attribute in the JSON response
            echo "error"
            jq -r .message <<< $resp >&2
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *) # Otherwise it means the module was installed, nothing to do
            ;;
        esac
    - if ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module uninstall."
    - log: Module ${this.module_symname} v${this.module_version} has been started

  uninstallOldVersionsOfModule:
    # Uninstalls all the previous versions of a module. If only one version is installed, nothing is done.
    # If the module is not installed, returns an error.
    #
    # Parameters:
    #   - module_symname: the module to clean
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - log: Uninstalling old versions of ${this.module_symname} module
    - cmd [proc]: |-
        resp=$(${this.curl} "localhost/modules/api/bundles/${this.module_symname}/*/_localInfo")
        case "$(jq -r ". | length" <<< $resp)" in
          "0") # Means the module is not installed
            echo "error"
            echo "The module is not installed, please check" >&2
            ;;
          "1") # Only one version installed, nothing to do
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *)
            jq -r "keys[]" <<< $resp | awk -F'/' '{print $NF}' | sort -nr | sed '1d' | tr "\n" ";" | sed 's/.$//'
            ;;
        esac
    - if ("${response.out}" == ""):
        log: Only one version of ${this.module_symname} installed, nothing to do
    - elif ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module installation."
    - else:
        - log: "Versions to delete for ${this.module_symname} module: ${response.out}"
        - script: |-
            return {"result": 0, "versions": "${response.out}".split(";")}
        - forEach(response.versions):
            - uninstallModuleVersion:
                module_symname: ${this.module_symname}
                module_version: ${@i}
        - log: Old versions of ${this.module_symname} module uninstalled

  uninstallModule:
    # Uninstalls all the versions of a module If the module is not installed, nothing is done.
    #
    # Parameters:
    #   - module_symname: the module to clean
    - set:
        curl: 'curl -SsH "Authorization: APIToken ${globals.__secret__pat_token}"'
    - getPatTokenAndKey
    - log: Uninstalling all versions of ${this.module_symname} module
    - cmd[proc]: |-
        resp=$(${this.curl} "localhost/modules/api/bundles/${this.module_symname}/*/_localInfo")
        case "$(jq -r ". | length" <<< $resp)" in
          "0") # Means the module is not installed
            echo "not installed"
            ;;
          "") # if response is not JSON, for instance 401 unauthorized
            echo "error"
            echo $resp >&2
            ;;
          *)
            printf $(jq -r "keys[]" <<< $resp | awk -F'/' '{print $NF}' | sort -nr) | tr "\n" ";"
            ;;
        esac
    - if ("${response.out}" == "not installed"):
        log: The module is not installed, nothing to do
    - elif ("${response.out}" == "error"):
        - return:
            type: error
            message: "An error occurred during module uninstall."
    - else:
        - log: "Versions to delete for ${this.module_symname} module: ${response.out}"
        - script: |-
            return {"result": 0, "versions": "${response.out}".split(";")}
        - forEach(response.versions):
            - uninstallModuleVersion:
                module_symname: ${this.module_symname}
                module_version: ${@i}
        - log: ${this.module_symname} module completely uninstalled

  ####################
  # proxysql related #
  ####################
  setupProxysqlCluster:
    - cmd[cp, proc]: |-
          ${globals.proxysql_cli} -e "DELETE FROM proxysql_servers"
    - foreach (nodes.cp):
        - cmd[cp, proc]: |-
            ${globals.proxysql_cli} -e "INSERT INTO proxysql_servers (hostname,port,weight,comment) VALUES ('node${@i.id}-${env.domain}',6032,0,'browsing_$((${@}+1))')"
    - cmd [cp, proc]: |-
        ${globals.proxysql_cli} -e "INSERT INTO proxysql_servers (hostname,port,weight,comment) VALUES ('node${nodes.proc.first.id}-${env.domain}',6032,0,'processing')"
        ${globals.proxysql_cli} -e "LOAD PROXYSQL SERVERS TO RUNTIME"
        ${globals.proxysql_cli} -e "SAVE PROXYSQL SERVERS TO DISK"
    - cmd [cp, proc]: |-
        i=60
        sql="select count(*) from stats_proxysql_servers_metrics where Uptime_s = 0"
        while ! sleep 1 && ${globals.proxysql_cli} -e "$sql" | grep -s 0; do
          ((i--))
          if [ $i -eq 0 ]; then
            echo "[ERROR] ProxySQL cluster is not healthy" 1>&2
            exit 1
          fi
        done
    - if (nodes.sqldb.length == 1):
        configureProxysqlForSingleDBNode

  configureProxysqlForSingleDBNode:
    cmd[cp, proc]: |-
      ${globals.proxysql_cli} -e "DELETE FROM mysql_servers WHERE hostgroup_id!=2;"
      ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections) VALUES (2,'galera_1',3306, 50)"
      ${globals.proxysql_cli} -e "UPDATE mysql_galera_hostgroups SET active=0;"
      ${globals.proxysql_cli} -e "LOAD MYSQL SERVERS TO RUNTIME;"
      ${globals.proxysql_cli} -e "SAVE MYSQL SERVERS TO DISK;"

  setupMysqlServers:
    - cmd[proc]: |-
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections) VALUES (2,'galera_1',3306, 50)"
    - if (nodes.sqldb.length > 1):
        - cmd[proc]: |-
            ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections) VALUES (2,'galera_2',3306, 50)"
            ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_3',3306, 50, 1000)"
    - cmd[proc]: |-
        ${globals.proxysql_cli} -e "LOAD MYSQL SERVERS TO RUNTIME"
        ${globals.proxysql_cli} -e "SAVE MYSQL SERVERS TO DISK"

  setupMonitorUser:
    - cmd[sqldb]: |-
        mysql -e "CREATE USER IF NOT EXISTS 'proxysql'@'%' IDENTIFIED BY 'monitorpassword'"
        mysql -e "GRANT SELECT on sys.* TO 'proxysql'@'%'"
        mysql -e "GRANT SELECT on performance_schema.* TO 'proxysql'@'%'"
        mysql -e "GRANT  PROCESS, REPLICATION CLIENT ON *.* TO 'proxysql'@'%'"

  enableBackendMonitor:
    - cmd[cp, proc]: |-
        ${globals.proxysql_cli} -e "UPDATE global_variables SET variable_value='true' WHERE variable_name='mysql-monitor_enabled'"
        ${globals.proxysql_cli} -e "LOAD MYSQL VARIABLES TO RUNTIME"
        ${globals.proxysql_cli} -e "SAVE MYSQL VARIABLES TO DISK"

  finishProxysqlInstall:
    - setupMonitorUser
    - enableBackendMonitor
    - if (nodes.sqldb.length > 1):
        - setupMysqlServers
    - else:
        - disableDatadogCustomChecks
    - setupProxysqlCluster

  refreshProxysqlInstancesList:
    - setupProxysqlCluster

  proxysqlSetMariadbBackendStatus:
    - cmd[cp, proc]: |-
        ${globals.proxysql_cli} -e "UPDATE mysql_servers SET status='${this.newStatus}' WHERE hostname='${this.targetHost}';"

  getGaleraMaster:
    # Return:
    #   - galeraMasterIndex
    - cmd[proc]: |-
        ${globals.proxysql_cli} -BNe "select DISTINCT hostname from runtime_mysql_servers where weight = 1000"
    - setGlobals:
        - galeraMasterIndex: ${response.out}

  proxysqlSwitchMaster:
    # Parameter:
    #   - target: galera number (1,2,3)
    - cmd[proc, cp]: |-
        # Check that the future master node is online
        res=$(${globals.proxysql_cli} -BNe "select * from runtime_mysql_servers where hostname='galera_${this.target}' and hostgroup_id=2 and status='ONLINE';")
        if [ -z "$res" ];then
          echo "The new masterNode is not online in proxySQL configuration" >> /var/log/jelastic-packages/proxySqlSwitchMaster.log
          exit 0
        fi

    - cmd[proc, cp]: |-
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_1',3306, 50, 1);"
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_2',3306, 50, 1);"
        ${globals.proxysql_cli} -e "REPLACE INTO mysql_servers(hostgroup_id,hostname,port, max_connections, weight) VALUES (2,'galera_3',3306, 50, 1);"
        ${globals.proxysql_cli} -e "update mysql_servers set weight=1000 where hostname='galera_${this.target}';"
        ${globals.proxysql_cli} -e "LOAD MYSQL SERVERS TO RUNTIME;"
        ${globals.proxysql_cli} -e "SAVE MYSQL SERVERS TO DISK"
        sleep 15

    - cmd[proc, cp]: |-
        # Check that there is only a single node with a weight of 1000
        res=$(${globals.proxysql_cli} -BNe "select * from runtime_mysql_servers where weight=1000 group by hostname;" | wc -l)
        if [ $res -lt 1 ];then
          echo "There is no master node with a weight of 1000 in proxysql runtime configuration" >> /var/log/jelastic-packages/proxySqlSwitchMaster.log
          exit 1
        elif [ $res -gt 1 ]; then
          echo "There is more than one master node with a weight of 1000 in proxysql runtime configuration" >> /var/log/jelastic-packages/proxySqlSwitchMaster.log
          exit 1
        fi

    - cmd[sqldb]: |-
        my_ip=$(grep $(hostname) /etc/hosts | awk '{print $1}')
        my_node_name_index=$(awk -v my_ip="$my_ip galera" '$0 ~my_ip {print $2}' /etc/hosts)
        if [[ "$my_node_name_index" == "galera_${this.target}" ]]; then
          exit 0
        fi
        timeout=600 # wait for 600s
        tries=0
        request="select COUNT(*) from INFORMATION_SCHEMA.PROCESSLIST where db='jahia' and user like 'jahia-db-%'"
        while [[ $(mysql -BNe "$request") -gt 0 ]]; do
          if [[ $tries -ge $timeout ]]; then
            echo "There are still open connections on $my_node_name_index"
            exit 1
          fi
          tries=`expr $tries + 10`
          sleep 10
        done

  disableDatadogCustomChecks:
    - cmd[cp, proc]: |-
        p="/etc/datadog-agent/conf.d"
        for check in proxysql_backend_missing proxysql_connections_discrepancies; do
          [ -h $p/${check}.yaml ] && mv $p/${check}.yaml $p/${check}.yaml_disabled
        done
        if systemctl -q is-active datadog-agent; then
          systemctl restart datadog-agent
        fi
      user: root

  procUpgrade:
    # Parameters:
    #   - upgradeJahia: true or false (false = rolling redeploy)
    #   - targetDockerTag: jahia version string (eg: 8.0.2.0)
    #   - useExistingVolumes: true or false
    - cmd [proc]:
        - echo 'export JAHIA_UPGRADE="${this.upgradeJahia}"' >> /etc/locale.conf
      user: root
    - api: environment.control.RedeployContainersByGroup
      nodeGroup: proc
      tag: ${this.targetDockerTag}
      useExistingVolumes: ${this.useExistingVolumes}
      skipReinstall: false
      envName: ${env.envName}
    # restore-module-state is not compatible with rolling redeploy
    - if (${this.upgradeJahia}):
        - cmd [proc]: |-
            rm -fr /data/digital-factory-data/bundles-deployed/*
            sudo -u tomcat touch "/data/digital-factory-data/[persisted-bundles].dorestore"
            echo "restore-module-state have been asked"
            ls -l /data/digital-factory-data/*.dorestore
            touch /data/digital-factory-data/modules/*
            service tomcat start
          user: root
    - cmd [proc]:
        - sed '/JAHIA_UPGRADE/d' -i /etc/locale.conf
      user: root
    - startupJahiaHealthCheck: ${nodes.proc.first.id}

  bulkCpUpgrade:
    # Parameters:
    #   - targetDockerTag: jahia version string (eg: 8.0.2.0)
    #   - useExistingVolumes: true or false
    - cmd [proc]: |-
        ## [Upgrade] - 2/2
        exit 0
    - api: environment.control.RedeployContainersByGroup
      nodeGroup: cp
      tag: ${this.targetDockerTag}
      useExistingVolumes: ${this.useExistingVolumes}
      skipReinstall: false
      envName: ${env.envName}

  rollingCpUpgrade:
    # Parameters:
    #   - targetDockerTag: jahia version string (eg: 8.0.2.0)
    #   - useExistingVolumes: true or false
    - cmd [proc]: |-
        ## [Upgrade] - 2/2
        exit 0
    - forEach (nodes.cp):
        - api: environment.control.RedeployContainerById
          nodeId: ${@i.id}
          tag: ${this.targetDockerTag}
          useExistingVolumes: ${this.useExistingVolumes}
          skipReinstall: false
          envName: ${env.envName}

  setVersionPropertiesValue:
    # Parameters:
    #   - currentJahiaVersion: Jahia version string (eg: "7.3.7.0")
    #   - targetJahiaVersion: Jahia version string (eg: "8.0.3.0")
    # Add jahia version in /data/digital-factory-data/info/version.properties before redeploy
    # in case we upgrade from a version that does not handle it to a version that does,
    # namely if we upgrade from Jahia < 7.3.8.0 to Jahia >= 7.3.8.0
    - isVersionStrictlyLower:
        a: "${this.currentJahiaVersion}"
        b: "7.3.8.0"
        res: isCurrentVersionStriclyLowerThan7380
    - isVersionHigherOrEqual:
        a: "${this.targetJahiaVersion}"
        b: "7.3.8.0"
        res: isTargetVersionHigherOrEqual7380

    - if ( ${globals.isCurrentVersionStriclyLowerThan7380} && ${globals.isTargetVersionHigherOrEqual7380} ):
        cmd[proc,cp]: |-
          INFO_DIR="/data/digital-factory-data/info"
          if [ ! -f $INFO_DIR/version.properties ]; then
            mkdir -p $INFO_DIR
            echo "version=${this.currentJahiaVersion}" > $INFO_DIR/version.properties
          fi
        user: tomcat

  cleanJRLocalRevisionsTable:
    - cmd [${nodes.sqldb.first.id}]: |-
        mysql jahia -Nse "SELECT revision_id FROM JR_J_LOCAL_REVISIONS WHERE journal_id LIKE 'processing.%'"
        mysql jahia -e "TRUNCATE JR_J_LOCAL_REVISIONS"

    - cmd [cp, proc]: |-
        node_name=$(awk '$1=="cluster.node.serverId" {print $NF; exit}' /opt/tomcat/conf/digital-factory-config/jahia/jahia.node.properties)
        current_revision=${response.out}
        mysql -E -u $DB_USER -p$DB_PASSWORD -h 127.0.0.1 -D jahia -P6033 -e "INSERT INTO JR_J_LOCAL_REVISIONS values ('$node_name',$current_revision)"
    - cleanJRJJournalTable:
        batchSize: 100000


  cleanJRJJournalTable:
    # Parameters:
    #   - batchSize: the number of lines to delete per batch
    - cmd [proc]: |-
        batch_size=${this.batchSize}
        sql_cmd="mysql -u $DB_USER -p$DB_PASSWORD -h 127.0.0.1 -D jahia -P6033"
        query="SELECT MIN(REVISION_ID) FROM JR_J_LOCAL_REVISIONS;"
        min_revision_number=$($sql_cmd -sN -e "$query")
        if [ $? -ne 0 ]; then
          echo "Can't get the minimum revision number, aborting"
          exit 1
        fi
        query="DELETE FROM JR_J_JOURNAL WHERE REVISION_ID < $min_revision_number ORDER BY REVISION_ID LIMIT $batch_size"
        echo "Deleting rows with revision_id < $min_revision_number in table JR_J_JOURNAL. Batch size: $batch_size"
        n=1
        while true; do
          result=$($sql_cmd -vv -e "$query")
          if [ $? -ne 0 ]; then
            echo "Error when trying to delete the rows, aborting"
            exit 1
          fi
          if echo $result | grep -q " 0 rows affected"; then
            exit 0
          fi
          echo "Batch #$n executed"
          ((n+=1))
          sleep 2
        done

  setupPat:
    # Parameters:
    # jahia_version: the jahia version
    - generatePatAndKey
    - savePatInVault:
        __secret__pat_token: ${globals.__secret__pat_token}
        __secret__pat_key: ${globals.__secret__pat_key}
    - setPatInJahia:
        __secret__pat_token: ${globals.__secret__pat_token}
        jahia_version: ${this.jahiaVersion}
    - setPatInHaproxy:
        __secret__pat_token: ${globals.__secret__pat_token}

  generatePatAndKey:
    - cmd[proc]: |-
        graph_token=$(cat /dev/urandom | tr -dc '[[:graph:]]' | fold -w 32 | head -n 1)
        token=$(echo -n "$graph_token" | base64)
        key=$(echo -n "$graph_token" | awk '{printf substr($1,0,16)}' | od -A n -t x1 | awk '{printf "%s%s%s%s-%s%s-%s%s-%s%s-%s%s%s%s%s%s",$1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16}')
        printf '{"hideThisOutput": true, "token": "%s", "key": "%s"}' "$token" "$key"

    - script: |-
        __secret__response = ${response.out};
        token = __secret__response["token"];
        key = __secret__response["key"];

        return {
          "result": 0,
          "onAfterReturn": {
            setGlobals: {
              "__secret__pat_token": token,
              "__secret__pat_key": key,
            }
          }
        };

  savePatInVault:
    # Parameters:
    #  - __secret__pat_token: PAT token
    #  - __secret__pat_key: PAT key
    - getVaultData
    - vaultSecretSet:
        secretPath: "paas/customers/${globals.organizationName}/paas_${env.shortdomain}/PAT/root"
        __secret__secretData: '{"token":"${this.__secret__pat_token}","key":"${this.__secret__pat_key}"}'

  setPatInJahia:
    # Parameters:
    # __secret__pat_token: the personal access token
    # jahia_version: the jahia version
    - cmd[proc]: |-
        __secret__pat_token=${this.__secret__pat_token}
        groovy_file_path=/data/digital-factory-data/patches/groovy/pat.groovy

        # Clean up any possible remainder of previous script execution
        rm -f ${groovy_file_path}*

        jahia_major_version=$(echo "${this.jahia_version}" | cut -d'.' -f1)
        if [ $jahia_major_version -eq 7 ]; then
          jahia_7_parameter=", null"
        else
          jahia_7_parameter=""
        fi

        echo """
        org.jahia.services.content.JCRTemplate.getInstance().doExecuteWithSystemSession({ session ->
          org.jahia.osgi.BundleUtils.getOsgiService(\"org.jahia.modules.apitokens.TokenService\"$jahia_7_parameter)
              .tokenBuilder(\"/users/root\", \"Jahia Cloud Token\", session)
              .setToken(\"$__secret__pat_token\")
              .setActive(true)
              .create()
          session.save();
        })
        """ >> $groovy_file_path

  setPatInHaproxy:
    # Parameters:
    # __secret__pat_token: the personal access token
    - script: |-
        return jelastic.env.control.AddContainerEnvVars(
          '${env.envName}',
          session,
          nodeGroup='bl',
          vars={"jahia_cfg_healthcheck_token": "${this.__secret__pat_token}"}
        );

  getPatTokenAndKey:
    # set token value in __secret__pat_token and key value in __secret__pat_key if not already set
    - if ("HideThisLine" && "${globals.__secret__pat_token.print()}" == "" || "${globals.__secret__pat_key.print()}" == ""):
        - getVaultData
        - vaultSecretReadAllKeysB64:
            secretPath: "paas/customers/${globals.organizationName}/paas_${env.shortdomain}/PAT/root"
        - script: |-
            __secret__pat_creds_base64 = "${globals.vaultSecretData}";
            pat_creds = JSON.parse(java.lang.String(java.util.Base64.getDecoder().decode(__secret__pat_creds_base64)))
            return {
              "result": 0,
              "onAfterReturn": {
                setGlobals: {
                  "__secret__pat_token": pat_creds["token"],
                  "__secret__pat_key": pat_creds["key"]
                }
              }
            };

  checkPatGroovyScriptExecution:
    - cmd[proc]: |-
        groovy_file_path=/data/digital-factory-data/patches/groovy/pat.groovy
        jahia_running_timeout=360 # 6 minutes
        sleep_interval=5

        while [ -f $groovy_file_path ]; do
          sleep $sleep_interval;
          ((jahia_running_timeout-=sleep_interval))
          if [ $jahia_running_timeout -eq 0 ]; then
            echo "[ERROR] $groovy_file_path is still not executed after 360 seconds"
            exit 1
          fi
        done

        rm -f $groovy_file_path.installed

        if [ -f $groovy_file_path.failed ]; then
            echo "[ERROR] pat.groovy execution failed"
            exit 1
        fi

  #######################
  # jexperience related #
  #######################
  getEnvLinkedJcustomer:
    # Parameters:
    #   - envName: jahia env name to fetch info from
    - script: |
        const envName = "${this.envName}";

        unomi_linked = jelastic.env.control.GetNodeGroups(envName, session).object.filter(function (object) {
                                        return object.name == "cp";}).pop().envLink;

        return unomi_linked?
        {"result": 0, value: unomi_linked, "is_linked": true, "out": "Found a linked env"} :
        {"result": 0, value: "none", "is_linked": false, "out": "No unomi env linked"};
    - setGlobals:
        unomi_env_name: ${response.value}
        unomi_env_linked: ${response.is_linked}

  checkJexperienceCfg:
    # Parameters:
    #   - jcustomerDns: jahia env name to fetch info from
    #   - jcustomerPwdB64: Jcustomer password (base64 encoded)
    - cmd[proc]: |-
        CONFIG_FILE="/data/digital-factory-data/karaf/etc/org.jahia.modules.jexperience.settings-global.cfg"
        URL=$(grep jexperience.jCustomerURL $CONFIG_FILE | cut -d'=' -f2 | sed 's/ //g' |sed 's/https\?...//g')
        if [ "$URL" != "${this.jcustomerDns}" ]; then
          >&2 echo "error"
        fi
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "jCustomer url is wrong."
    - cmd[proc]: |-
        CONFIG_FILE="/data/digital-factory-data/karaf/etc/org.jahia.modules.jexperience.settings-global.cfg"
        PASSWD=$(sed -n 's/\( *jexperience.jCustomerPassword *= *\)\(.*\) *$/\2/p' $CONFIG_FILE | tr -d '\n' | base64)
        if [ "$PASSWD" != "$(echo -n ${this.jcustomerPwdB64})" ]; then
          >&2 echo "error"
        fi
    - if ("${response.errOut}" != ""):
        - return:
            type: error
            message: "jCustomer password is wrong."

  emptyJexperienceConfigAndRemoveJexperienceJar:
    - cmd[proc, cp]: |-
        JCUSTOMER_CONFIG_FILE="/data/digital-factory-data/karaf/etc/org.jahia.modules.jexperience.settings-global.cfg"
        if [ -f $JCUSTOMER_CONFIG_FILE ]; then
         sed -i 's/\(jexperience.jCustomer.*=\).*/\1/g' $JCUSTOMER_CONFIG_FILE
        fi
    - uninstallModule:
        module_symname: jexperience

### Vault related actions ###
  vaultGetIPsecConfB64:
    # Returns:
    #   ${globals.vaultSecretData}: the IPsec conf, base64 encoded
    - getVaultData
    - vaultSecretReadKeyB64:
        secretPath: paas/customers/${globals.organizationName}/paas_${env.shortdomain}/ipsec/conn-1
        secretKey: conf
    - setGlobals:
        IPsecConfB64: ${globals.vaultSecretData}

  vaultGetIPsecPSKB64:
    # Returns:
    #   ${globals.vaultPSKB64}: the PSK, base64 encoded
    - getVaultData
    - vaultSecretReadKeyB64:
        secretPath: paas/customers/${globals.organizationName}/paas_${env.shortdomain}/ipsec/conn-1
        secretKey: secret
    - setGlobals:
        IPsecPSKB64: ${globals.vaultSecretData}
